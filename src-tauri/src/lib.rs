use anyhow::{anyhow, Context, Result};
use calamine::{open_workbook, Reader, Xls, Xlsx, Data};
use docx_rs::*;
use encoding_rs::{GBK, UTF_8};
use once_cell::sync::Lazy;
use quick_xml::events::Event;
use quick_xml::Reader as XmlReader;
use regex::Regex;
use rust_xlsxwriter::{Format, FormatAlign, Workbook};
use serde::{Deserialize, Serialize};
use std::fs;
use std::io::{Cursor, Read, Write};
use std::path::{Path, PathBuf};
use std::process::Command;
use tauri::{Manager, State};
use time::OffsetDateTime;
use uuid::Uuid;
use zip::{ZipArchive, ZipWriter};
use zip::write::FileOptions;


// æ–‡ä»¶åµŒå…¥ç›¸å…³ç»“æ„ä½“å’Œå‡½æ•°

/// åµŒå…¥å¼æ–‡ä»¶ç»“æ„
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct EmbeddedFile {
    pub id: String,
    pub name: String,
    pub path: String,
    pub data: Vec<u8>,
    pub content_type: String,
    pub file_type: FileType,
    pub zip_id: String,  // æ‰€å±ç« èŠ‚ID
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub enum FileType {
    Video,
    PDF,
    Image,
    Document,
    Excel,
    ZIP,
    Other(String),
}

/// æ–‡ä»¶åµŒå…¥é…ç½®
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct EmbeddingConfig {
    pub enabled: bool,
    pub max_file_size: usize,
    pub allowed_types: Vec<String>,
    pub exclude_patterns: Vec<String>,
}

impl Default for EmbeddingConfig {
    fn default() -> Self {
        Self {
            enabled: true,
            max_file_size: 50 * 1024 * 1024,  // 50MB
            allowed_types: vec![
                "pdf".to_string(),
                "mp4".to_string(),
                "avi".to_string(),
                "mov".to_string(),
                "wmv".to_string(),
                "jpg".to_string(),
                "jpeg".to_string(),
                "png".to_string(),
                "gif".to_string(),
                "bmp".to_string(),
                "doc".to_string(),
                "docx".to_string(),
                "txt".to_string(),
                "zip".to_string(),
            ],
            exclude_patterns: vec![
                "*.tmp".to_string(),
                "*.temp".to_string(),
                ".*".to_string(),
            ],
        }
    }
}

/// å¢å¼ºçš„æ±‡æ€»æ–‡æ¡£æ„å»ºï¼Œæ”¯æŒæ–‡ï¿½ï¿½åµŒå…¥
fn build_enhanced_summary_docx(
    batch: &BatchSummary,
    embed_files: bool,
) -> Result<(Docx, Vec<EmbeddedFile>)> {
    let mut docx = Docx::new();
    docx = docx.add_paragraph(
        Paragraph::new().add_run(Run::new().add_text("æ±‡æ€»æ–‡æ¡£").bold()),
    );

    let mut all_embedded_files = Vec::new();

    for z in &batch.zips {
        docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_text(format!(
            "æŒ‡ä»¤ç¼–å·:  {}",
            z.word.instruction_no
        ))));
        docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_text(format!(
            "æŒ‡ä»¤æ ‡é¢˜:  {}",
            z.word.title
        ))));
        docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_text(format!(
            "ä¸‹å‘æ—¶é—´:  {}",
            z.word.issued_at
        ))));

        // å¤„ç†æŒ‡ä»¤å†…å®¹ï¼ˆä¿æŒæ¢è¡Œæ ¼å¼ï¼‰
        if !z.word.content.trim().is_empty() {
            docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_text("æŒ‡ä»¤å†…å®¹:")));
            for line in z.word.content.lines() {
                let trimmed_line = line.trim();
                if !trimmed_line.is_empty() {
                    docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_text(trimmed_line)));
                } else {
                    docx = docx.add_paragraph(Paragraph::new());
                }
            }
        }

        // ç›´æ¥æ˜¾ç¤ºå›¾ç‰‡ï¼Œåˆ é™¤"å›¾ç‰‡"æ ‡é¢˜
        for img_path in &z.image_files {
            let bytes = fs::read(img_path)
                .with_context(|| format!("è¯»å–å›¾ç‰‡å¤±è´¥: {}", img_path))?;
            let pic = Pic::new(&bytes);
            docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_image(pic)));
        }

        // ç›´æ¥æ˜¾ç¤ºPDFå›¾ç‰‡ï¼Œåˆ é™¤"PDFé¡µé¢å›¾ç‰‡:"æ ‡é¢˜
        
        // ç›´æ¥æ˜¾ç¤ºPDFæˆªå›¾ï¼Œåˆ é™¤"PDFé¡µé¢æˆªå›¾:"æ ‡é¢˜
        for img_path in &z.pdf_page_screenshot_files {
            let bytes = fs::read(img_path)
                .with_context(|| format!("è¯»å–PDFé¡µé¢æˆªå›¾å¤±è´¥: {}", img_path))?;
            let pic = Pic::new(&bytes);
            docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_image(pic)));
        }

        // æ·»åŠ ç« èŠ‚æ ‡è®°æ®µè½ï¼ˆç”¨äºåç»­æ’å…¥OLEå¯¹è±¡ï¼‰
        let marker = format!("EMBED_MARKER_{}", z.id);
        docx = docx.add_paragraph(
            Paragraph::new().add_run(Run::new().add_text(&marker).size(2).color("FFFFFF"))
        );

        // æ”¶é›†éœ€è¦åµŒå…¥çš„æ–‡ä»¶ï¼ˆåŒ…æ‹¬è§†é¢‘ã€PDFã€Excelã€ZIPï¼Œä¸åŒ…æ‹¬å›¾ç‰‡ï¼‰
        if embed_files {
            // åµŒå…¥è§†é¢‘æ–‡ä»¶
            for video_path in &z.video_files {
                if Path::new(video_path).exists() {
                    if let Ok(embed_file) = create_embedded_file(video_path, &z.id) {
                        all_embedded_files.push(embed_file);
                    }
                }
            }

            // åµŒå…¥PDFæ–‡ä»¶
            for pdf_path in &z.pdf_files {
                if Path::new(pdf_path).exists() {
                    if let Ok(embed_file) = create_embedded_file(pdf_path, &z.id) {
                        all_embedded_files.push(embed_file);
                    }
                }
            }

            // åµŒå…¥Excelæ–‡ä»¶
            for excel_path in &z.excel_files {
                if Path::new(excel_path).exists() {
                    if let Ok(embed_file) = create_embedded_file(excel_path, &z.id) {
                        all_embedded_files.push(embed_file);
                    }
                }
            }

            // åµŒå…¥åŸå§‹ZIPæ–‡ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if z.include_original_zip {
                let zip_path = &z.stored_path;
                if Path::new(zip_path).exists() {
                    if let Ok(embed_file) = create_embedded_file(zip_path, &z.id) {
                        all_embedded_files.push(embed_file);
                    }
                }
            }
        }

        // åœ¨ä¸åŒç« èŠ‚ä¹‹é—´æ·»åŠ ç©ºè¡Œï¼Œæé«˜å¯è¯»æ€§
        docx = docx.add_paragraph(Paragraph::new());
    }

    // è¿”å›æ–‡æ¡£å’ŒåµŒå…¥æ–‡ä»¶åˆ—è¡¨ï¼Œè®©è°ƒç”¨è€…å¤„ç†æœ€ç»ˆçš„æ„å»º
    Ok((docx, all_embedded_files))
}

fn create_embedded_file(path: &str, zip_id: &str) -> Result<EmbeddedFile> {
    let data = fs::read(path)
        .with_context(|| format!("Failed to read file: {}", path))?;

    let name = Path::new(path)
        .file_name()
        .unwrap_or_default()
        .to_string_lossy()
        .to_string();

    let file_type = detect_file_type(&name);
    let content_type = get_content_type(&name);

    Ok(EmbeddedFile {
        id: format!("embed_{}", uuid::Uuid::new_v4().to_string().replace("-", "")),
        name,
        path: path.to_string(),
        data,
        content_type,
        file_type,
        zip_id: zip_id.to_string(),
    })
}

fn detect_file_type(filename: &str) -> FileType {
    let filename_lower = filename.to_lowercase();

    if filename_lower.ends_with(".mp4") || filename_lower.ends_with(".avi") ||
       filename_lower.ends_with(".mov") || filename_lower.ends_with(".wmv") ||
       filename_lower.ends_with(".mkv") || filename_lower.ends_with(".flv") {
        FileType::Video
    } else if filename_lower.ends_with(".pdf") {
        FileType::PDF
    } else if filename_lower.ends_with(".jpg") || filename_lower.ends_with(".jpeg") ||
              filename_lower.ends_with(".png") || filename_lower.ends_with(".gif") ||
              filename_lower.ends_with(".bmp") || filename_lower.ends_with(".webp") {
        FileType::Image
    } else if filename_lower.ends_with(".zip") {
        FileType::ZIP
    } else if filename_lower.ends_with(".xls") || filename_lower.ends_with(".xlsx") {
        FileType::Excel
    } else if filename_lower.ends_with(".doc") || filename_lower.ends_with(".docx") ||
              filename_lower.ends_with(".txt") || filename_lower.ends_with(".rtf") {
        FileType::Document
    } else {
        if let Some(ext) = Path::new(filename).extension() {
            FileType::Other(ext.to_string_lossy().to_string())
        } else {
            FileType::Other("unknown".to_string())
        }
    }
}

fn get_content_type(filename: &str) -> String {
    let filename_lower = filename.to_lowercase();

    match filename_lower.as_str() {
        f if f.ends_with(".pdf") => "application/pdf".to_string(),
        f if f.ends_with(".mp4") => "video/mp4".to_string(),
        f if f.ends_with(".avi") => "video/x-msvideo".to_string(),
        f if f.ends_with(".mov") => "video/quicktime".to_string(),
        f if f.ends_with(".wmv") => "video/x-ms-wmv".to_string(),
        f if f.ends_with(".mkv") => "video/x-matroska".to_string(),
        f if f.ends_with(".flv") => "video/x-flv".to_string(),
        f if f.ends_with(".jpg") || f.ends_with(".jpeg") => "image/jpeg".to_string(),
        f if f.ends_with(".png") => "image/png".to_string(),
        f if f.ends_with(".gif") => "image/gif".to_string(),
        f if f.ends_with(".bmp") => "image/bmp".to_string(),
        f if f.ends_with(".webp") => "image/webp".to_string(),
        f if f.ends_with(".zip") => "application/zip".to_string(),
        f if f.ends_with(".xls") => "application/vnd.ms-excel".to_string(),
        f if f.ends_with(".xlsx") => "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet".to_string(),
        f if f.ends_with(".doc") => "application/msword".to_string(),
        f if f.ends_with(".docx") => "application/vnd.openxmlformats-officedocument.wordprocessingml.document".to_string(),
        f if f.ends_with(".txt") => "text/plain".to_string(),
        f if f.ends_with(".rtf") => "application/rtf".to_string(),
        _ => "application/octet-stream".to_string(),
    }
}

fn get_file_icon(file_type: &FileType) -> &'static str {
    match file_type {
        FileType::Video => "ğŸ¥",
        FileType::PDF => "ğŸ“„",
        FileType::Image => "ğŸ–¼ï¸",
        FileType::Document => "ğŸ“",
        FileType::Excel => "ğŸ“Š",
        FileType::ZIP => "ğŸ“¦",
        FileType::Other(_) => "ğŸ“",
    }
}

/// æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æœ¬æ–‡ä»¶
fn is_text_file(content_type: &str) -> bool {
    content_type.starts_with("text/") ||
    content_type.contains("plain") ||
    content_type.contains("rtf") ||
    content_type.contains("html") ||
    content_type.contains("xml") ||
    content_type.contains("json") ||
    content_type.contains("csv")
}

/// æ„å»ºå¸¦åµŒå…¥æ–‡ä»¶çš„ DOCXï¼ˆçœŸæ­£çš„ OLE åµŒå…¥ï¼‰
fn build_docx_with_embeddings(
    base_docx: Docx,
    embedded_files: &[EmbeddedFile]
) -> Result<Vec<u8>> {
    // 1. é¦–å…ˆç”ŸæˆåŸºç¡€çš„ DOCX
    let xmldocx = base_docx.build();
    let mut base_bytes = Vec::new();
    {
        let mut cursor = Cursor::new(&mut base_bytes);
        xmldocx.pack(&mut cursor)?;
    }

    // 2. å¦‚æœæ²¡æœ‰æ–‡ä»¶è¦åµŒå…¥ï¼Œç›´æ¥è¿”å›
    if embedded_files.is_empty() {
        return Ok(base_bytes);
    }

    println!("=== OLE æ–‡ä»¶åµŒå…¥æ¨¡å¼ ===");
    println!("æ‰¾åˆ° {} ä¸ªé™„ä»¶æ–‡ä»¶:", embedded_files.len());
    for (i, file) in embedded_files.iter().enumerate() {
        println!("  {}. {} (å¤§å°: {:.1} MB, ç±»å‹: {})",
            i + 1,
            file.name,
            file.data.len() as f64 / 1024.0 / 1024.0,
            file.content_type
        );
    }

    // 3. æ‰§è¡ŒçœŸæ­£çš„ OLE åµŒå…¥
    match embed_ole_objects_into_docx(&base_bytes, embedded_files) {
        Ok(result) => {
            println!("âœ“ OLE å¯¹è±¡åµŒå…¥æˆåŠŸï¼");
            Ok(result)
        }
        Err(e) => {
            println!("âš  OLE åµŒå…¥å¤±è´¥: {}", e);
            println!("  è¿”å›åŸºç¡€æ–‡æ¡£ä»¥ç¡®ä¿åŠŸèƒ½æ­£å¸¸");
            Ok(base_bytes)
        }
    }
}

/// å°è¯•çœŸæ­£çš„æ–‡ä»¶åµŒå…¥
fn attempt_file_embedding(
    base_docx_bytes: &[u8],
    embedded_files: &[EmbeddedFile]
) -> Result<Vec<u8>> {
    // å¦‚æœæ²¡æœ‰æ–‡ä»¶è¦åµŒå…¥ï¼Œç›´æ¥è¿”å›
    if embedded_files.is_empty() {
        return Ok(base_docx_bytes.to_vec());
    }

    println!("å¼€å§‹çœŸæ­£çš„æ–‡ä»¶åµŒå…¥...");

    // æš‚æ—¶è¿”å›åŸºç¡€æ–‡æ¡£ï¼Œé¿å…æŸåç°æœ‰åŠŸèƒ½
    // OpenXMLæ“ä½œéå¸¸å¤æ‚ï¼Œå®¹æ˜“æŸåæ–‡æ¡£ç»“æ„
    println!("âš  OpenXMLæ–‡ä»¶åµŒå…¥æ“ä½œå¤æ‚ï¼Œä¸ºç¡®ä¿æ–‡æ¡£å®Œæ•´æ€§ï¼Œæš‚æ—¶ä½¿ç”¨æ˜¾ç¤ºæ¨¡å¼");
    println!("  æ˜¾ç¤ºçš„é™„ä»¶ä¿¡æ¯ï¼š");
    for file in embedded_files {
        println!("  - {} ({} bytes)", file.name, file.data.len());
    }

    Err(anyhow!("ä½¿ç”¨ç®€åŒ–æ˜¾ç¤ºæ¨¡å¼ç¡®ä¿æ–‡æ¡£å®Œæ•´æ€§"))
}

/// ç”ŸæˆåµŒå…¥æ–‡ä»¶çš„ Content_Types.xml
fn generate_content_types_xml(embedded_files: &[EmbeddedFile]) -> String {
    let mut types = r#"<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Types xmlns="http://schemas.openxmlformats.org/package/2006/content-types">
    <Default Extension="rels" ContentType="application/vnd.openxmlformats-package.relationships+xml"/>
    <Default Extension="xml" ContentType="application/xml"/>
    <Override PartName="/word/document.xml" ContentType="application/vnd.openxmlformats-officedocument.wordprocessingml.document.main+xml"/>
"#.to_string();

    // æ·»åŠ åµŒå…¥æ–‡ä»¶çš„ç±»å‹å®šä¹‰
    for file in embedded_files {
        let embed_path = format!("/word/embeddings/{}.bin", file.id);
        types.push_str(&format!(
            r#"    <Override PartName="{}" ContentType="{}"/>
"#, embed_path, file.content_type));
    }

    types.push_str("</Types>");
    types
}

/// ç”ŸæˆåµŒå…¥æ–‡ä»¶çš„ relationships.xml
fn generate_relationships_xml(embedded_files: &[EmbeddedFile]) -> String {
    let mut rels = r#"<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Relationships xmlns="http://schemas.openxmlformats.org/package/2006/relationships">
"#.to_string();

    // æ·»åŠ åµŒå…¥æ–‡ä»¶çš„å…³ç³»
    for (index, file) in embedded_files.iter().enumerate() {
        let r_id = format!("rId{}", index + 1);
        let target = format!("embeddings/{}.bin", file.id);
        rels.push_str(&format!(
            r#"    <Relationship Id="{}" Type="http://schemas.openxmlformats.org/officeDocument/2006/relationships/oleObject" Target="{}"/>
"#, r_id, target));
    }

    rels.push_str("</Relationships>");
    rels
}

/// ç”ŸæˆåŒ…å«åµŒå…¥æ–‡ä»¶çš„Content_Types.xml
fn build_content_types_with_embeds(embedded_files: &[EmbeddedFile]) -> String {
    let mut types = r#"<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Types xmlns="http://schemas.openxmlformats.org/package/2006/content-types">
    <Default Extension="rels" ContentType="application/vnd.openxmlformats-package.relationships+xml"/>
    <Default Extension="xml" ContentType="application/xml"/>
    <Default Extension="bin" ContentType="application/vnd.openxmlformats-officedocument.oleObject"/>
    <Override PartName="/word/document.xml" ContentType="application/vnd.openxmlformats-officedocument.wordprocessingml.document.main+xml"/>
    <Override PartName="/word/styles.xml" ContentType="application/vnd.openxmlformats-officedocument.wordprocessingml.styles+xml"/>
    <Override PartName="/word/settings.xml" ContentType="application/vnd.openxmlformats-officedocument.wordprocessingml.settings+xml"/>
    <Override PartName="/word/fontTable.xml" ContentType="application/vnd.openxmlformats-officedocument.wordprocessingml.fontTable+xml"/>
    <Override PartName="/word/numbering.xml" ContentType="application/vnd.openxmlformats-officedocument.wordprocessingml.numbering.xml"/>
    <Override PartName="/docProps/core.xml" ContentType="application/vnd.openxmlformats-package.core-properties+xml"/>
    <Override PartName="/docProps/app.xml" ContentType="application/vnd.openxmlformats-officedocument.extended-properties+xml"/>
    <Override PartName="/word/webSettings.xml" ContentType="application/vnd.openxmlformats-officedocument.wordprocessingml.webSettings+xml"/>
"#.to_string();

    // æ·»åŠ åµŒå…¥æ–‡ä»¶çš„ç±»å‹å®šä¹‰
    for file in embedded_files {
        let embed_path = format!("/word/embeddings/{}",
            sanitize_filename(&format!("{}.{}",
                Path::new(&file.name).file_stem()
                    .unwrap_or_default()
                    .to_string_lossy(),
                Path::new(&file.name)
                    .extension()
                    .unwrap_or_default()
                    .to_string_lossy()
            ))
        );

        types.push_str(&format!(
            r#"    <Override PartName="{}" ContentType="{}"/>
"#, embed_path, file.content_type));
    }

    types.push_str("</Types>");
    types
}

/// åœ¨document.xmlä¸­æ·»åŠ åµŒå…¥å¯¹è±¡å¼•ç”¨
fn add_embedded_objects_to_document(document_xml: &str, embedded_files: &[EmbeddedFile]) -> Result<String> {
    // æ‰¾åˆ°bodyæ ‡ç­¾çš„ç»“æŸä½ç½®ï¼Œå¹¶åœ¨é‚£é‡Œæ’å…¥åµŒå…¥å¯¹è±¡
    let body_end_pattern = r"</w:body>";

    if !document_xml.contains(body_end_pattern) {
        return Err(anyhow!("æ–‡æ¡£ä¸­æœªæ‰¾åˆ°bodyç»“æŸæ ‡ç­¾"));
    }

    let mut objects_xml = String::new();

    for (_, file) in embedded_files.iter().enumerate() {
        let file_icon = match file.file_type {
            FileType::PDF => "ğŸ“„",
            FileType::Video => "ğŸ¥",
            FileType::ZIP => "ğŸ“¦",
            _ => "ğŸ“"
        };

        // åˆ›å»ºç®€åŒ–çš„åµŒå…¥å¯¹è±¡æ®µè½ - ä½¿ç”¨ç®€å•çš„è¶…é“¾æ¥æ–¹å¼ï¼Œè¿™åœ¨Wordä¸­æ›´å¯é 
        objects_xml.push_str(&format!(
            r#"<w:p><w:r><w:rPr><w:color w:val="0000FF"/><w:u w:val="single"/></w:rPr><w:t>{icon} {name} (åŒå‡»æ‰“å¼€é™„ä»¶)</w:t></w:r></w:p>"#,
            icon = file_icon,
            name = file.name
        ));
    }

    // æ›¿æ¢bodyç»“æŸæ ‡ç­¾
    let modified_document = document_xml.replace(body_end_pattern, &format!("{}\n{}", objects_xml, body_end_pattern));

    Ok(modified_document)
}

/// ç”ŸæˆåŒ…å«åµŒå…¥æ–‡ä»¶çš„å…³ç³»æ–‡æ¡£
fn build_relationships_with_embeds(embedded_files: &[EmbeddedFile]) -> String {
    let mut rels = r#"<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Relationships xmlns="http://schemas.openxmlformats.org/package/2006/relationships">
"#.to_string();

    // æ·»åŠ åµŒå…¥æ–‡ä»¶çš„å…³ç³»
    for (index, file) in embedded_files.iter().enumerate() {
        let r_id = format!("rId{}", index + 1);
        let safe_filename = sanitize_filename(&format!("{}.{}",
            Path::new(&file.name).file_stem()
                .unwrap_or_default()
                .to_string_lossy(),
            Path::new(&file.name)
                .extension()
                .unwrap_or_default()
                .to_string_lossy()
        ));
        let target = format!("embeddings/{}", safe_filename);

        rels.push_str(&format!(
            r#"    <Relationship Id="{}" Type="http://schemas.openxmlformats.org/officeDocument/2006/relationships/oleObject" Target="{}"/>
"#, r_id, target));
    }

    rels.push_str("</Relationships>");
    rels
}

/// æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ä¸å®‰å…¨å­—ç¬¦
fn sanitize_filename(filename: &str) -> String {
    let unsafe_chars = ['<', '>', ':', '"', '/', '\\', '|', '?', '*'];
    let mut result = String::new();

    for c in filename.chars() {
        if unsafe_chars.contains(&c) {
            // ç”¨ä¸‹åˆ’çº¿æ›¿æ¢ä¸å®‰å…¨å­—ç¬¦
            result.push('_');
        } else {
            result.push(c);
        }
    }

    result
}

// ==================== OLE åµŒå…¥æ ¸å¿ƒåŠŸèƒ½ ====================

/// å°† OLE å¯¹è±¡åµŒå…¥åˆ° DOCX æ–‡ä»¶ä¸­ï¼ˆä¸»å‡½æ•°ï¼‰
fn embed_ole_objects_into_docx(
    docx_bytes: &[u8],
    embedded_files: &[EmbeddedFile]
) -> Result<Vec<u8>> {
    // 1. æ‰“å¼€ç°æœ‰çš„ DOCX (ZIP æ ¼å¼)
    let reader = Cursor::new(docx_bytes);
    let mut zip_archive = ZipArchive::new(reader)?;

    // 2. åˆ›å»ºè¾“å‡º ZIP
    let output_cursor = Cursor::new(Vec::new());
    let mut zip_writer = ZipWriter::new(output_cursor);

    // 3. å¤åˆ¶æ‰€æœ‰ç°æœ‰æ–‡ä»¶ï¼ˆé™¤äº†éœ€è¦ä¿®æ”¹çš„ï¼‰
    let files_to_modify = vec![
        "word/document.xml",
        "word/_rels/document.xml.rels",
        "[Content_Types].xml"
    ];

    for i in 0..zip_archive.len() {
        let mut file = zip_archive.by_index(i)?;
        let name = file.name().to_string();

        if !files_to_modify.contains(&name.as_str()) {
            // å¤åˆ¶æ–‡ä»¶
            let options = FileOptions::default()
                .compression_method(zip::CompressionMethod::Deflated);
            zip_writer.start_file(&name, options)?;
            std::io::copy(&mut file, &mut zip_writer)?;
        }
    }

    // 4. è¯»å–éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶
    let document_xml = read_file_from_zip_archive(&mut zip_archive, "word/document.xml")?;
    let rels_xml = read_file_from_zip_archive(&mut zip_archive, "word/_rels/document.xml.rels")?;
    let content_types_xml = read_file_from_zip_archive(&mut zip_archive, "[Content_Types].xml")?;

    // 5. æ·»åŠ åµŒå…¥æ–‡ä»¶å’Œå›¾æ ‡
    let next_rid = get_next_relationship_id(&rels_xml);

    for (index, file) in embedded_files.iter().enumerate() {
        // åˆ›å»º OLE Package
        let ole_package = create_ole_package(file)?;
        let ole_filename = format!("word/embeddings/oleObject{}.bin", index + 1);

        let options = FileOptions::default()
            .compression_method(zip::CompressionMethod::Deflated);
        zip_writer.start_file(&ole_filename, options)?;
        zip_writer.write_all(&ole_package)?;

        // æ·»åŠ å›¾æ ‡æ–‡ä»¶
        let icon_data = get_default_emf_icon(&file.file_type, &file.name);
        let icon_filename = format!("word/media/image{}.emf", index + 1);

        zip_writer.start_file(&icon_filename, options)?;
        zip_writer.write_all(&icon_data)?;
    }

    // 6. ä¿®æ”¹ document.xml - æ·»åŠ  OLE å¯¹è±¡
    let modified_document = add_ole_objects_to_document_xml(&document_xml, embedded_files, next_rid)?;
    let options = FileOptions::default()
        .compression_method(zip::CompressionMethod::Deflated);
    zip_writer.start_file("word/document.xml", options)?;
    zip_writer.write_all(modified_document.as_bytes())?;

    // 7. ä¿®æ”¹ document.xml.rels - æ·»åŠ å…³ç³»
    let modified_rels = add_ole_relationships_to_rels(&rels_xml, embedded_files, next_rid)?;
    zip_writer.start_file("word/_rels/document.xml.rels", options)?;
    zip_writer.write_all(modified_rels.as_bytes())?;

    // 8. ä¿®æ”¹ [Content_Types].xml - æ·»åŠ å†…å®¹ç±»å‹
    let modified_content_types = add_ole_content_types(&content_types_xml)?;
    zip_writer.start_file("[Content_Types].xml", options)?;
    zip_writer.write_all(modified_content_types.as_bytes())?;

    // 9. å®Œæˆå¹¶è·å–æ•°æ®
    let output_cursor = zip_writer.finish()?;
    let output_bytes = output_cursor.into_inner();

    Ok(output_bytes)
}

/// åˆ›å»º OLE Package æ ¼å¼ï¼ˆOLE å¤åˆæ–‡æ¡£ï¼‰
/// åŸºäºçœŸå® Word æ–‡æ¡£ä¸­çš„ Ole10Native æ ¼å¼
fn create_ole_package(file: &EmbeddedFile) -> Result<Vec<u8>> {
    // åˆ›å»º Ole10Native æµæ•°æ®
    let mut native_data = Vec::new();

    // çœŸå®çš„ Ole10Native æµæ ¼å¼ï¼ˆæ¥è‡ªå®é™…çš„Wordæ–‡æ¡£åˆ†æï¼‰ï¼š
    // [4 bytes] æ–‡ä»¶å¤§å°ï¼ˆå°ç«¯ï¼‰
    // [2 bytes] å›ºå®šæ ‡è®° 0x02 0x00
    // [å˜é•¿] GBKç¼–ç çš„å®Œæ•´æ–‡ä»¶å + null terminator (0x00)
    // [å˜é•¿] åŸå§‹æ–‡ä»¶è·¯å¾„ + null terminator
    // [3 bytes] åˆ†éš”ç¬¦ 0x00 0x00 0x03
    // [1 byte] Windowsä¸´æ—¶è·¯å¾„é•¿åº¦
    // [å˜é•¿] Windowsä¸´æ—¶è·¯å¾„ + null terminator
    // [4 bytes] æ–‡ä»¶æ•°æ®å¤§å°ï¼ˆå°ç«¯ï¼‰
    // [å˜é•¿] å®é™…æ–‡ä»¶æ•°æ®

    // å°†æ–‡ä»¶åè½¬æ¢ä¸ºGBKç¼–ç ï¼ˆWindows ANSIç¼–ç ï¼‰
    let (filename_bytes, _, _) = encoding_rs::GBK.encode(&file.name);
    let filename_gbk = filename_bytes.as_ref();

    // 1. æ–‡ä»¶å¤§å°ï¼ˆ4å­—èŠ‚ï¼Œå°ç«¯ï¼‰
    native_data.extend_from_slice(&(file.data.len() as u32).to_le_bytes());

    // 2. å›ºå®šæ ‡è®°ï¼ˆ2å­—èŠ‚ï¼‰
    native_data.extend_from_slice(&[0x02, 0x00]);

    // 3. å®Œæ•´æ–‡ä»¶åï¼ˆGBKç¼–ç ï¼‰+ null terminator
    native_data.extend_from_slice(filename_gbk);
    native_data.push(0);

    // 4. åŸå§‹æ–‡ä»¶è·¯å¾„ï¼ˆä½¿ç”¨ç®€åŒ–è·¯å¾„ï¼‰+ null terminator
    let original_path = format!("C:/{}", file.name);
    let (path_bytes, _, _) = encoding_rs::GBK.encode(&original_path);
    native_data.extend_from_slice(path_bytes.as_ref());
    native_data.push(0);

    // 5. è·¯å¾„åçš„åˆ†éš”ç¬¦ï¼ˆæ­£ç¡®æ ¼å¼ï¼‰
    // ä¸¤ä¸ªé¢å¤–çš„ null + 0x03 + 0x00
    native_data.push(0);
    native_data.push(0);
    native_data.push(0x03);
    native_data.push(0x00);

    // 6. Windowsä¸´æ—¶è·¯å¾„é•¿åº¦ï¼ˆ4å­—èŠ‚å°ç«¯ï¼‰+ è·¯å¾„ + null terminator
    let temp_path = format!("C:\\Users\\Public\\{}", file.name);
    let (temp_path_bytes, _, _) = encoding_rs::GBK.encode(&temp_path);

    // ä¸´æ—¶è·¯å¾„é•¿åº¦ï¼ˆåŒ…æ‹¬null terminatorï¼Œ4å­—èŠ‚å°ç«¯ï¼‰
    let temp_path_len = (temp_path_bytes.len() + 1) as u32;
    native_data.extend_from_slice(&temp_path_len.to_le_bytes());

    // ä¸´æ—¶è·¯å¾„ + null terminator
    native_data.extend_from_slice(temp_path_bytes.as_ref());
    native_data.push(0);

    // 7. æ–‡ä»¶æ•°æ®å¤§å°ï¼ˆ4å­—èŠ‚ï¼Œå°ç«¯ï¼‰
    native_data.extend_from_slice(&(file.data.len() as u32).to_le_bytes());

    // 8. å®é™…æ–‡ä»¶æ•°æ®
    native_data.extend_from_slice(&file.data);

    // åˆ›å»º OLE å¤åˆæ–‡æ¡£
    let mut output = Cursor::new(Vec::new());
    {
        let mut comp = cfb::CompoundFile::create(&mut output)?;

        // å†™å…¥ \x01Ole10Native æµ
        comp.create_stream("\x01Ole10Native")?;
        let mut stream = comp.open_stream("\x01Ole10Native")?;
        stream.write_all(&native_data)?;
        drop(stream); // æ˜¾å¼å…³é—­æµ

        // æ·»åŠ  OLE å¯¹è±¡çš„æ ‡å‡†æµ
        // \x01CompObj æµ - æè¿°å¯¹è±¡ç±»å‹
        comp.create_stream("\x01CompObj")?;
        let mut comp_obj_stream = comp.open_stream("\x01CompObj")?;
        let comp_obj_data = create_comp_obj_stream(&file.name);
        comp_obj_stream.write_all(&comp_obj_data)?;
        drop(comp_obj_stream); // æ˜¾å¼å…³é—­æµ

        // ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½å†™å…¥
        drop(comp);
    }

    Ok(output.into_inner())
}

/// åˆ›å»º CompObj æµæ•°æ®
fn create_comp_obj_stream(_filename: &str) -> Vec<u8> {
    let mut data = Vec::new();

    // ç‰ˆæœ¬ (2 bytes)
    data.extend_from_slice(&0x0001u16.to_le_bytes());

    // Byte order (2 bytes)
    data.extend_from_slice(&0xFFFEu16.to_le_bytes());

    // Format version (4 bytes)
    data.extend_from_slice(&0x00000A03u32.to_le_bytes());

    // Reserved (4 bytes)
    data.extend_from_slice(&0xFFFFFFFFu32.to_le_bytes());

    // CLSID (16 bytes) - Package çš„ CLSID: {0003000C-0000-0000-C000-000000000046}
    data.extend_from_slice(&[
        0x0C, 0x00, 0x00, 0x00,
        0x00, 0x00,
        0x00, 0x00,
        0xC0, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x46
    ]);

    // User type string (length + string)
    let user_type = "Package";
    data.extend_from_slice(&(user_type.len() as u32).to_le_bytes());
    data.extend_from_slice(user_type.as_bytes());
    data.push(0); // Null terminator

    // Clipboard format name (empty)
    data.extend_from_slice(&0u32.to_le_bytes());

    // Reserved (4 bytes)
    data.extend_from_slice(&0x00000000u32.to_le_bytes());

    data
}

/// å†™å…¥å¸¦é•¿åº¦å‰ç¼€çš„ UTF-16 å­—ç¬¦ä¸²
fn write_utf16_length_prefixed_string(buffer: &mut Vec<u8>, s: &str) {
    let utf16: Vec<u16> = s.encode_utf16().collect();
    let byte_len = (utf16.len() * 2) as u32;

    // å†™å…¥é•¿åº¦ï¼ˆå­—èŠ‚æ•°ï¼‰
    buffer.extend_from_slice(&byte_len.to_le_bytes());

    // å†™å…¥ UTF-16 å­—ç¬¦ä¸²
    for code_unit in utf16 {
        buffer.extend_from_slice(&code_unit.to_le_bytes());
    }
}

/// è·å–å¯¹åº”æ–‡ä»¶ç±»å‹çš„ EMF å›¾æ ‡
/// æ™ºèƒ½æˆªæ–­æ–‡ä»¶åä½¿å…¶é€‚åˆæŒ‡å®šçš„æœ€å¤§å­—èŠ‚æ•°ï¼ˆUTF-16LEç¼–ç ï¼‰
/// ä¿ç•™æ–‡ä»¶æ‰©å±•åï¼Œåœ¨åˆé€‚çš„ä½ç½®æˆªæ–­ä¸»æ–‡ä»¶å
fn truncate_filename_to_bytes(filename: &str, max_bytes: usize) -> String {
    use std::path::Path;

    // è®¡ç®—å½“å‰æ–‡ä»¶åçš„UTF-16LEå­—èŠ‚æ•°
    let current_bytes: Vec<u8> = filename.encode_utf16()
        .flat_map(|c| c.to_le_bytes())
        .collect();

    // å¦‚æœå·²ç»é€‚åˆï¼Œç›´æ¥è¿”å›
    if current_bytes.len() <= max_bytes {
        return filename.to_string();
    }

    // åˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å
    let path = Path::new(filename);
    let extension = path.extension()
        .and_then(|e| e.to_str())
        .unwrap_or("");
    let stem = path.file_stem()
        .and_then(|s| s.to_str())
        .unwrap_or(filename);

    // è®¡ç®—æ‰©å±•åçš„å­—èŠ‚æ•°ï¼ˆåŒ…æ‹¬ç‚¹å·ï¼‰
    let ext_with_dot = if !extension.is_empty() {
        format!(".{}", extension)
    } else {
        String::new()
    };
    let ext_bytes: Vec<u8> = ext_with_dot.encode_utf16()
        .flat_map(|c| c.to_le_bytes())
        .collect();

    // ä½¿ç”¨æ›´çŸ­çš„çœç•¥å·ï¼ˆ2ä¸ªç‚¹è€Œä¸æ˜¯3ä¸ªï¼‰
    let ellipsis = "..";
    let ellipsis_bytes: Vec<u8> = ellipsis.encode_utf16()
        .flat_map(|c| c.to_le_bytes())
        .collect();

    // è®¡ç®—ä¸»æ–‡ä»¶åå¯ç”¨çš„å­—èŠ‚æ•°
    let available_for_stem = max_bytes.saturating_sub(ext_bytes.len() + ellipsis_bytes.len());

    if available_for_stem < 4 {
        // ç©ºé—´å¤ªå°ï¼Œåªè¿”å›æ‰©å±•åæˆ–æˆªæ–­çš„æ–‡ä»¶å
        let chars: Vec<char> = filename.chars().collect();
        let max_chars = max_bytes / 2; // UTF-16LEæ¯ä¸ªå­—ç¬¦æœ€å°‘2å­—èŠ‚
        return chars.iter().take(max_chars.saturating_sub(1)).collect();
    }

    // äºŒåˆ†æŸ¥æ‰¾æœ€å¤šå¯ä»¥ä¿ç•™å¤šå°‘ä¸ªå­—ç¬¦
    let stem_chars: Vec<char> = stem.chars().collect();
    let mut left = 0;
    let mut right = stem_chars.len();
    let mut best_len = 0;

    while left <= right {
        let mid = (left + right) / 2;
        let test_stem: String = stem_chars.iter().take(mid).collect();
        let test_bytes: Vec<u8> = test_stem.encode_utf16()
            .flat_map(|c| c.to_le_bytes())
            .collect();

        if test_bytes.len() <= available_for_stem {
            best_len = mid;
            left = mid + 1;
        } else {
            right = mid - 1;
        }
    }

    // æ™ºèƒ½è°ƒæ•´æˆªæ–­ä½ç½®ï¼šé¿å…åœ¨ä¸­è‹±æ–‡æ··åˆå¤„æˆªæ–­
    let truncated_stem: String = stem_chars.iter().take(best_len).collect();

    // æ£€æŸ¥æœ€åä¸€ä¸ªå­—ç¬¦ï¼Œå¦‚æœæ˜¯ASCIIå­—æ¯ï¼Œå°è¯•å‘å‰æ‰¾åˆ°åˆ†éš”ç¬¦æˆ–ä¸­æ–‡å­—ç¬¦
    let final_stem = if best_len > 0 && best_len < stem_chars.len() {
        let last_char = stem_chars[best_len - 1];

        // å¦‚æœæœ€åæ˜¯ASCIIå­—æ¯ï¼Œå°è¯•å‘å‰æ‰¾åˆ°æ›´å¥½çš„æˆªæ–­ç‚¹
        if last_char.is_ascii_alphabetic() {
            // å‘å‰æŸ¥æ‰¾åˆ†éš”ç¬¦æˆ–ä¸­æ–‡å­—ç¬¦
            let mut better_pos = best_len;
            for i in (0..best_len).rev() {
                let ch = stem_chars[i];
                // åœ¨åˆ†éš”ç¬¦ã€ç©ºæ ¼ã€ä¸­æ–‡å­—ç¬¦ç­‰è‡ªç„¶è¾¹ç•Œå¤„æˆªæ–­
                if ch == '_' || ch == '-' || ch == ' ' || ch == '.' ||
                   ch > '\u{4E00}' && ch < '\u{9FFF}' { // ä¸­æ–‡å­—ç¬¦èŒƒå›´
                    better_pos = i;
                    break;
                }
                // å¦‚æœæ‰¾åˆ°äº†ä¸­æ–‡å­—ç¬¦ï¼Œåœ¨å…¶åæˆªæ–­
                if i > 0 {
                    let prev_ch = stem_chars[i - 1];
                    if (prev_ch > '\u{4E00}' && prev_ch < '\u{9FFF}') &&
                       ch.is_ascii_alphabetic() {
                        better_pos = i;
                        break;
                    }
                }
            }

            // åªæœ‰åœ¨æ–°ä½ç½®åˆç†æ—¶æ‰ä½¿ç”¨ï¼ˆä¸è¦ç¼©çŸ­å¤ªå¤šï¼‰
            if better_pos > best_len / 2 {
                stem_chars.iter().take(better_pos).collect()
            } else {
                truncated_stem
            }
        } else {
            truncated_stem
        }
    } else {
        truncated_stem
    };

    format!("{}{}{}", final_stem, ellipsis, ext_with_dot)
}

/// åœ¨EMFå›¾æ ‡æ•°æ®ä¸­æ›¿æ¢ç¡¬ç¼–ç çš„æ–‡ä»¶å
/// EMFå›¾æ ‡æ–‡ä»¶ä¸­åŒ…å«äº†åŸå§‹æ–‡ä»¶åçš„UTF-16LEç¼–ç å­—ç¬¦ä¸²
///
/// é‡è¦ï¼šå¯ç”¨ç©ºé—´å°±æ˜¯æ—§æ–‡ä»¶åçš„é•¿åº¦ï¼Œä¸è¦è¦†ç›–åé¢çš„EMFå…ƒæ•°æ®ï¼
fn replace_filename_in_emf(mut emf_data: Vec<u8>, old_filename: &str, new_filename: &str) -> Vec<u8> {
    // å°†æ–‡ä»¶åè½¬æ¢ä¸ºUTF-16LEç¼–ç 
    let old_utf16: Vec<u8> = old_filename.encode_utf16()
        .flat_map(|c| c.to_le_bytes())
        .collect();

    // åœ¨EMFæ•°æ®ä¸­æŸ¥æ‰¾æ—§æ–‡ä»¶å
    if let Some(pos) = emf_data.windows(old_utf16.len())
        .position(|window| window == old_utf16.as_slice()) {

        println!("æ‰¾åˆ°ç¡¬ç¼–ç æ–‡ä»¶å '{}' åœ¨åç§» 0x{:x}", old_filename, pos);

        // å¯ç”¨ç©ºé—´ = æ—§æ–‡ä»¶åçš„é•¿åº¦ï¼ˆä¸è¦å‘åæŸ¥æ‰¾null-nullï¼Œé‚£ä¼šè¦†ç›–EMFå…ƒæ•°æ®ï¼ï¼‰
        let available_space = old_utf16.len();

        // æ™ºèƒ½æˆªæ–­æ–‡ä»¶åä»¥é€‚åº”å¯ç”¨ç©ºé—´
        let final_filename = truncate_filename_to_bytes(new_filename, available_space);
        let new_utf16: Vec<u8> = final_filename.encode_utf16()
            .flat_map(|c| c.to_le_bytes())
            .collect();

        let new_filename_bytes = new_filename.encode_utf16().count() * 2;
        println!("å¯ç”¨ç©ºé—´: {} å­—èŠ‚, åŸæ–‡ä»¶åéœ€è¦: {} å­—èŠ‚",
                 available_space,
                 new_filename_bytes);

        if final_filename != new_filename {
            println!("âš  æ–‡ä»¶åå·²æˆªæ–­: '{}' -> '{}'", new_filename, final_filename);
        }

        // æ›¿æ¢æ–‡ä»¶å
        for (i, &byte) in new_utf16.iter().enumerate() {
            emf_data[pos + i] = byte;
        }

        // ç”¨nullå¡«å……å‰©ä½™ç©ºé—´ï¼ˆä»…å¡«å……åˆ°æ—§æ–‡ä»¶åé•¿åº¦ï¼Œä¸è¦è¶…å‡ºï¼‰
        for i in new_utf16.len()..available_space {
            emf_data[pos + i] = 0;
        }

        println!("âœ“ æˆåŠŸæ›¿æ¢æ–‡ä»¶åä¸º '{}'", final_filename);
    } else {
        println!("âš  æœªåœ¨EMFå›¾æ ‡ä¸­æ‰¾åˆ°ç¡¬ç¼–ç æ–‡ä»¶å '{}'", old_filename);
    }

    emf_data
}

fn get_default_emf_icon(file_type: &FileType, filename: &str) -> Vec<u8> {
    // æ ¹æ®æ–‡ä»¶ç±»å‹è¿”å›å¯¹åº”çš„EMFå›¾æ ‡
    // è¿™äº›å›¾æ ‡æ˜¯ä»çœŸå®çš„Wordæ–‡æ¡£ä¸­æå–çš„ï¼ŒåŒ…å«ç¡¬ç¼–ç çš„æ–‡ä»¶å
    // æˆ‘ä»¬éœ€è¦å°†ç¡¬ç¼–ç çš„æ–‡ä»¶åæ›¿æ¢ä¸ºå®é™…æ–‡ä»¶å

    let (icon_data, old_filename) = match file_type {
        FileType::Video => {
            const ICON: &[u8] = include_bytes!("../icon_video.emf");
            (ICON.to_vec(), "qqerçš„æŠ–éŸ³_.mp4")
        },
        FileType::PDF => {
            const ICON: &[u8] = include_bytes!("../icon_pdf.emf");
            (ICON.to_vec(), "0_1æ·±å­”åˆ»èš€ï¼Œå¯åŠ©300å±‚3D NANDåˆ¶é€  - ä»Šæ—¥å¤´æ¡.pdf")
        },
        FileType::Excel => {
            const ICON: &[u8] = include_bytes!("../icon_excel.emf");
            (ICON.to_vec(), "20_074644.xlsx")
        },
        FileType::Document => {
            // æ–‡æ¡£ç±»å‹ä½¿ç”¨Excelå›¾æ ‡ï¼ˆ.doc, .docxç­‰ï¼‰
            const ICON: &[u8] = include_bytes!("../icon_excel.emf");
            (ICON.to_vec(), "20_074644.xlsx")
        },
        FileType::ZIP => {
            const ICON: &[u8] = include_bytes!("../icon_zip.emf");
            (ICON.to_vec(), "ZL1.zip")
        },
        FileType::Image | FileType::Other(_) => {
            // å›¾ç‰‡å’Œå…¶ä»–ç±»å‹ä½¿ç”¨é€šç”¨Packageå›¾æ ‡ï¼ˆä¸åŒ…å«ç¡¬ç¼–ç æ–‡ä»¶åï¼‰
            const ICON: &[u8] = include_bytes!("../ole_package_icon.emf");
            return ICON.to_vec();
        },
    };

    // æ›¿æ¢EMFä¸­çš„ç¡¬ç¼–ç æ–‡ä»¶åä¸ºå®é™…æ–‡ä»¶å
    replace_filename_in_emf(icon_data, old_filename, filename)
}

/// ä» ZIP archive ä¸­è¯»å–æ–‡ä»¶
fn read_file_from_zip_archive(archive: &mut ZipArchive<Cursor<&[u8]>>, path: &str) -> Result<String> {
    let mut file = archive.by_name(path)
        .with_context(|| format!("æ— æ³•æ‰¾åˆ°æ–‡ä»¶: {}", path))?;
    let mut content = String::new();
    file.read_to_string(&mut content)?;
    Ok(content)
}

/// è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„å…³ç³» ID
fn get_next_relationship_id(rels_xml: &str) -> usize {
    let mut max_id = 0;

    // æŸ¥æ‰¾æ‰€æœ‰ rId å¹¶æ‰¾åˆ°æœ€å¤§å€¼
    for cap in regex::Regex::new(r#"Id="rId(\d+)""#).unwrap().captures_iter(rels_xml) {
        if let Some(num_str) = cap.get(1) {
            if let Ok(num) = num_str.as_str().parse::<usize>() {
                max_id = max_id.max(num);
            }
        }
    }

    max_id + 1
}

/// åœ¨ document.xml ä¸­æ·»åŠ  OLE å¯¹è±¡
fn add_ole_objects_to_document_xml(
    document_xml: &str,
    embedded_files: &[EmbeddedFile],
    start_rid: usize
) -> Result<String> {
    let mut result = document_xml.to_string();

    println!("=== æ·»åŠ  OLE å¯¹è±¡åˆ° document.xml ===");
    println!("åµŒå…¥æ–‡ä»¶æ•°é‡: {}", embedded_files.len());

    // æŒ‰ zip_id åˆ†ç»„åµŒå…¥æ–‡ä»¶ï¼Œä½†ä¿æŒåŸå§‹ç´¢å¼•
    use std::collections::HashMap;
    let mut files_by_zip: HashMap<String, Vec<(usize, &EmbeddedFile)>> = HashMap::new();
    for (index, file) in embedded_files.iter().enumerate() {
        files_by_zip.entry(file.zip_id.clone())
            .or_insert_with(Vec::new)
            .push((index, file));
    }

    println!("æŒ‰ç« èŠ‚åˆ†ç»„åçš„æ•°é‡: {}", files_by_zip.len());

    // ä¸ºæ¯ä¸ªç« èŠ‚ç”ŸæˆOLEå¯¹è±¡XMLå¹¶æ’å…¥
    for (zip_id, files) in files_by_zip.iter() {
        let marker = format!("EMBED_MARKER_{}", zip_id);
        println!("å¤„ç†ç« èŠ‚: {}, æ–‡ä»¶æ•°: {}, æ ‡è®°: {}", zip_id, files.len(), marker);

        let mut objects_xml = String::new();

        for (index, file) in files.iter() {
            let ole_rid = format!("rId{}", start_rid + index * 2);
            let img_rid = format!("rId{}", start_rid + index * 2 + 1);
            let shape_id = format!("_x0000_i{}", 1025 + index);
            let object_id = format!("_146807572{}", index);

            println!("  - æ–‡ä»¶ {}: {} (rid={}, img_rid={})", index, file.name, ole_rid, img_rid);

            objects_xml.push_str(&format!(r###"
<w:p w14:paraId="{paraId}"><w:pPr><w:rPr><w:rFonts w:hint="default"/><w:lang w:val="en-US"/></w:rPr></w:pPr><w:r><w:rPr><w:rFonts w:hint="default"/><w:lang w:val="en-US"/></w:rPr><w:object><v:shape id="{shape_id}" o:spt="75" type="#_x0000_t75" style="height:65.25pt;width:72.4pt;" o:ole="t" filled="f" o:preferrelative="t" stroked="f" coordsize="21600,21600"><v:fill on="f" focussize="0,0"/><v:stroke on="f"/><v:imagedata r:id="{img_rid}" o:title=""/><o:lock v:ext="edit" aspectratio="t"/><w10:wrap type="none"/><w10:anchorlock/></v:shape><o:OLEObject Type="Embed" ProgID="Package" ShapeID="{shape_id}" DrawAspect="Icon" ObjectID="{object_id}" r:id="{ole_rid}"><o:LockedField>false</o:LockedField></o:OLEObject></w:object></w:r></w:p>
"###,
                paraId = format!("{:08X}", 0x10000000 + index),
                shape_id = shape_id,
                img_rid = img_rid,
                ole_rid = ole_rid,
                object_id = object_id
            ));
        }

        // åœ¨æ ‡è®°æ®µè½ä¹‹åæ’å…¥OLEå¯¹è±¡
        // ç›´æ¥æœç´¢æ ‡è®°æ–‡æœ¬ï¼Œä¸ç®¡XMLæ ‡ç­¾æ ¼å¼
        if let Some(pos) = result.find(&marker) {
            println!("  âœ“ æ‰¾åˆ°æ ‡è®°æ–‡æœ¬ä½ç½®: {}", pos);
            // ä»æ ‡è®°ä½ç½®å‘åæŸ¥æ‰¾æ®µè½ç»“æŸæ ‡ç­¾
            if let Some(end_pos) = result[pos..].find("</w:p>") {
                let insert_pos = pos + end_pos + "</w:p>".len();
                println!("  âœ“ æ’å…¥ä½ç½®: {}", insert_pos);
                result.insert_str(insert_pos, &objects_xml);
            } else {
                println!("  âœ— æœªæ‰¾åˆ°æ®µè½ç»“æŸæ ‡ç­¾");
            }
        } else {
            println!("  âœ— æœªæ‰¾åˆ°æ ‡è®°æ–‡æœ¬: {}", marker);
        }
    }

    Ok(result)
}

/// åœ¨ document.xml.rels ä¸­æ·»åŠ  OLE å¯¹è±¡å…³ç³»
fn add_ole_relationships_to_rels(
    rels_xml: &str,
    embedded_files: &[EmbeddedFile],
    start_rid: usize
) -> Result<String> {
    let mut new_rels = String::new();

    for (index, _file) in embedded_files.iter().enumerate() {
        let ole_rid = format!("rId{}", start_rid + index * 2);
        let img_rid = format!("rId{}", start_rid + index * 2 + 1);
        let ole_target = format!("embeddings/oleObject{}.bin", index + 1);
        let img_target = format!("media/image{}.emf", index + 1);

        new_rels.push_str(&format!(
            r#"<Relationship Id="{}" Type="http://schemas.openxmlformats.org/officeDocument/2006/relationships/oleObject" Target="{}"/>"#,
            ole_rid, ole_target
        ));
        new_rels.push_str(&format!(
            r#"<Relationship Id="{}" Type="http://schemas.openxmlformats.org/officeDocument/2006/relationships/image" Target="{}"/>"#,
            img_rid, img_target
        ));
    }

    // åœ¨ </Relationships> ä¹‹å‰æ’å…¥æ–°å…³ç³»
    let result = rels_xml.replace("</Relationships>", &format!("{}</Relationships>", new_rels));

    Ok(result)
}

/// åœ¨ [Content_Types].xml ä¸­æ·»åŠ  OLE å¯¹è±¡å†…å®¹ç±»å‹
fn add_ole_content_types(content_types_xml: &str) -> Result<String> {
    // æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ .bin å’Œ .emf çš„å®šä¹‰
    let mut result = content_types_xml.to_string();

    if !result.contains(r#"Extension="bin""#) {
        result = result.replace(
            "</Types>",
            r#"<Default Extension="bin" ContentType="application/vnd.openxmlformats-officedocument.oleObject"/></Types>"#
        );
    }

    if !result.contains(r#"Extension="emf""#) {
        result = result.replace(
            "</Types>",
            r#"<Default Extension="emf" ContentType="image/x-emf"/></Types>"#
        );
    }

    Ok(result)
}

// ==================== OLE åµŒå…¥åŠŸèƒ½ç»“æŸ ====================

static RE_FIELD: Lazy<Regex> = Lazy::new(|| {
    Regex::new(
        r"(?m)^\s*(æŒ‡ä»¤ç¼–å·|æŒ‡ä»¤æ ‡é¢˜|ä¸‹å‘æ—¶é—´|æŒ‡ä»¤å†…å®¹)\s*[:ï¼š]\s*(?P<v>.*?)\s*$",
    )
    .expect("valid regex")
});

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
struct WordFields {
    instruction_no: String,
    title: String,
    issued_at: String,
    content: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ZipSummary {
    id: String,
    filename: String,
    source_path: String,
    stored_path: String,
    extracted_dir: String,
    #[serde(default)]
    include_original_zip: bool,
    status: String,
    word: WordFields,
    has_video: bool,
    has_sample: bool,
    video_entries: Vec<String>,
    video_files: Vec<String>,
    image_files: Vec<String>,
    pdf_files: Vec<String>,
    pdf_page_screenshot_files: Vec<String>,
    excel_files: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct BatchSummary {
    batch_id: String,
    created_at: i64,
    zips: Vec<ZipSummary>,
}

#[derive(Default)]
struct AppState {
    last_batch_id: std::sync::Mutex<Option<String>>,
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
struct ExportZipSelection {
    zip_id: String,
    include: bool,
    include_original_zip: bool,
    selected_video_indices: Vec<usize>,
    selected_image_indices: Vec<usize>,
    selected_pdf_indices: Vec<usize>,
    selected_excel_indices: Vec<usize>,
    selected_pdf_page_screenshot_indices: Vec<usize>,
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
struct ExportBundleSelection {
    zips: Vec<ExportZipSelection>,
}

fn app_data_dir(app: &tauri::AppHandle) -> Result<PathBuf> {
    let dir = app
        .path()
        .app_data_dir()
        .context("æ— æ³•è·å–AppDataç›®å½•")?
        .join("ArchiveBox");
    fs::create_dir_all(&dir)?;
    Ok(dir)
}

fn batch_dir(app: &tauri::AppHandle, batch_id: &str) -> Result<PathBuf> {
    let dir = app_data_dir(app)?.join("batches").join(batch_id);
    fs::create_dir_all(&dir)?;
    Ok(dir)
}

fn prompt_save_path(default_name: String, ext: &str, filter_label: &str) -> Result<PathBuf, String> {
    let chosen = rfd::FileDialog::new()
        .add_filter(filter_label, &[ext])
        .set_file_name(&default_name)
        .save_file();
    let Some(path) = chosen else {
        return Err("å·²å–æ¶ˆ".to_string());
    };
    let path = ensure_extension(path, ext);
    if let Some(parent) = path.parent() {
        fs::create_dir_all(parent).map_err(err_to_string)?;
    }
    Ok(path)
}

fn ensure_extension(path: PathBuf, ext: &str) -> PathBuf {
    match path.extension().and_then(|e| e.to_str()) {
        Some(_) => path,
        None => path.with_extension(ext),
    }
}

fn default_export_excel_name(now: OffsetDateTime) -> String {
    format!(
        "å¯¼å‡ºç»“æœ_{}{:02}{:02}_{:02}{:02}{:02}.xlsx",
        now.year(),
        now.month() as u8,
        now.day(),
        now.hour(),
        now.minute(),
        now.second()
    )
}

fn default_export_bundle_name(now: OffsetDateTime) -> String {
    format!(
        "æ±‡æ€»åŒ…_{}{:02}{:02}_{:02}{:02}{:02}",
        now.year(),
        now.month() as u8,
        now.day(),
        now.hour(),
        now.minute(),
        now.second()
    )
}

#[tauri::command]
fn pick_zip_files() -> Result<Vec<String>, String> {
    let files = rfd::FileDialog::new()
        .add_filter("ZIP", &["zip"])
        .pick_files()
        .unwrap_or_default();
    Ok(files
        .into_iter()
        .map(|p| p.to_string_lossy().to_string())
        .collect())
}

#[tauri::command]
fn import_zips(app: tauri::AppHandle, state: State<'_, AppState>, paths: Vec<String>) -> Result<BatchSummary, String> {
    let now = OffsetDateTime::now_utc();
    let batch_id = format!("batch_{}", now.unix_timestamp());
    let batch_dir = batch_dir(&app, &batch_id).map_err(err_to_string)?;

    let mut zips = Vec::new();
    for p in paths {
        let source_path = PathBuf::from(&p);
        let filename = source_path
            .file_name()
            .and_then(|s| s.to_str())
            .unwrap_or("UNKNOWN.zip")
            .to_string();
        let zip_id = Uuid::new_v4().to_string();

        let stored_zip_path = {
            let dir = batch_dir.join("zips").join(&zip_id);
            fs::create_dir_all(&dir).map_err(err_to_string)?;
            let dst = dir.join(&filename);
            fs::copy(&source_path, &dst).map_err(err_to_string)?;
            dst
        };

        let mut summary = ZipSummary {
            id: zip_id.clone(),
            filename: filename.clone(),
            source_path: p.clone(),
            stored_path: stored_zip_path.to_string_lossy().to_string(),
            extracted_dir: String::new(),
            include_original_zip: false,
            status: "processing".to_string(),
            word: WordFields::default(),
            has_video: false,
            has_sample: false,
            video_entries: vec![],
            video_files: vec![],
            image_files: vec![],
            pdf_files: vec![],
            pdf_page_screenshot_files: vec![],
            excel_files: vec![],
        };

        let zip_scan = match scan_zip(&stored_zip_path) {
            Ok(v) => v,
            Err(e) => {
                summary.status = format!("failed: {e:#}");
                zips.push(summary);
                continue;
            }
        };

        let (word, video_entries) = match extract_word_and_videos(&stored_zip_path, &zip_scan) {
            Ok(v) => v,
            Err(e) => {
                summary.status = format!("failed: {e:#}");
                zips.push(summary);
                continue;
            }
        };

        summary.word = word;
        summary.has_sample = zip_scan.has_sample;
        summary.video_entries = video_entries;
        summary.has_video = !summary.video_entries.is_empty();

        // è§£å‹ç”¨äºé¢„è§ˆï¼ˆè§†é¢‘/å›¾ç‰‡/PDFï¼‰
        if let Err(e) = extract_preview_files(&batch_dir, &zip_id, &stored_zip_path, &zip_scan, &mut summary) {
            summary.status = format!("failed: {e:#}");
            zips.push(summary);
            continue;
        }

        summary.status = "completed".to_string();

        zips.push(summary);
    }

    let batch = BatchSummary {
        batch_id: batch_id.clone(),
        created_at: now.unix_timestamp(),
        zips,
    };

    let meta_path = batch_dir.join("batch.json");
    fs::write(&meta_path, serde_json::to_vec_pretty(&batch).map_err(err_to_string)?)
        .map_err(err_to_string)?;

    *state.last_batch_id.lock().unwrap() = Some(batch_id);
    Ok(batch)
}

#[tauri::command]
fn export_excel(app: tauri::AppHandle, batch_id: String) -> Result<String, String> {
    let batch_dir = batch_dir(&app, &batch_id).map_err(err_to_string)?;
    let mut batch: BatchSummary = read_batch(&batch_dir).map_err(err_to_string)?;
    // æŒ‰ä¸‹å‘æ—¶é—´æ’åº
    sort_zips_by_issued_at(&mut batch.zips);
    export_excel_impl(&app, &batch)
}

#[tauri::command]
fn export_excel_with_selection(
    app: tauri::AppHandle,
    batch_id: String,
    zip_ids: Vec<String>,
) -> Result<String, String> {
    let batch_dir = batch_dir(&app, &batch_id).map_err(err_to_string)?;
    let mut batch: BatchSummary = read_batch(&batch_dir).map_err(err_to_string)?;
    if !zip_ids.is_empty() {
        batch.zips.retain(|z| zip_ids.contains(&z.id));
    }
    // æŒ‰ä¸‹å‘æ—¶é—´æ’åº
    sort_zips_by_issued_at(&mut batch.zips);
    export_excel_impl(&app, &batch)
}

fn export_excel_impl(app: &tauri::AppHandle, batch: &BatchSummary) -> Result<String, String> {
    let now = OffsetDateTime::now_utc();
    let _ = app;
    let out = prompt_save_path(default_export_excel_name(now), "xlsx", "Excel")?;

    let mut workbook = Workbook::new();
    let worksheet = workbook.add_worksheet();

    let header_format = Format::new().set_bold().set_align(FormatAlign::Center);
    let headers = [
        "åºå·",
        "æ—¥æœŸ",
        "ç¼–ç ",
        "æ ‡é¢˜",
        "ç±»å‹",
        "æ ·æœ¬ï¼ˆè§†é¢‘ORå›¾æ–‡ï¼‰",
        "æ˜¯å¦æœ‰æ ·æœ¬",
        "æ˜¯å¦å¤šæ‰¹æ¬¡ä»»åŠ¡",
        "ä¸‹å‘æ—¶é—´",
        "ä»»åŠ¡æ‰§è¡Œ",
        "å¤‡æ³¨",
    ];
    for (i, h) in headers.iter().enumerate() {
        worksheet
            .write_string_with_format(0, i as u16, *h, &header_format)
            .map_err(err_to_string)?;
    }

    for (idx, z) in batch.zips.iter().enumerate() {
        let row = (idx + 1) as u32;
        let date = format!(
            "{:04}{:02}{:02}",
            now.year(),
            now.month() as u8,
            now.day()
        );
        let sample_kind = if !z.video_files.is_empty() || !z.video_entries.is_empty() {
            "è§†é¢‘"
        } else if !z.image_files.is_empty()
            || !z.pdf_page_screenshot_files.is_empty()
            || !z.excel_files.is_empty()
        {
            "å›¾æ–‡"
        } else {
            ""
        };
        let has_sample = if sample_kind.is_empty() { "å¦" } else { "æ˜¯" };

        worksheet
            .write_number(row, 0, (idx + 1) as f64)
            .map_err(err_to_string)?;
        worksheet
            .write_string(row, 1, &date)
            .map_err(err_to_string)?;
        worksheet
            .write_string(row, 2, z.word.instruction_no.trim())
            .map_err(err_to_string)?;
        worksheet
            .write_string(row, 3, z.word.title.trim())
            .map_err(err_to_string)?;
        worksheet
            .write_string(row, 4, z.word.title.trim())
            .map_err(err_to_string)?;
        worksheet
            .write_string(row, 5, sample_kind)
            .map_err(err_to_string)?;
        worksheet
            .write_string(row, 6, has_sample)
            .map_err(err_to_string)?;
        worksheet
            .write_string(row, 7, "å¦")
            .map_err(err_to_string)?;
        worksheet
            .write_string(row, 8, z.word.issued_at.trim())
            .map_err(err_to_string)?;
        worksheet
            .write_string(row, 9, "å·²å®Œæˆ")
            .map_err(err_to_string)?;
        worksheet.write_string(row, 10, "").map_err(err_to_string)?;
    }

    workbook
        .save(out.to_string_lossy().as_ref())
        .map_err(err_to_string)?;
    Ok(out.to_string_lossy().to_string())
}

#[tauri::command]
fn export_bundle_zip(app: tauri::AppHandle, batch_id: String) -> Result<String, String> {
    let batch_dir = batch_dir(&app, &batch_id).map_err(err_to_string)?;
    let mut batch: BatchSummary = read_batch(&batch_dir).map_err(err_to_string)?;

    // æŒ‰ä¸‹å‘æ—¶é—´æ’åº
    sort_zips_by_issued_at(&mut batch.zips);

    let now = OffsetDateTime::now_utc();
    let out = prompt_save_path(default_export_bundle_name(now), "zip", "ZIP")?;

    let docx_bytes = build_summary_docx(&batch).map_err(err_to_string)?;
    let bundle_bytes = build_bundle_zip_bytes(&batch, &docx_bytes).map_err(err_to_string)?;

    fs::write(&out, bundle_bytes).map_err(err_to_string)?;
    Ok(out.to_string_lossy().to_string())
}

#[tauri::command]
fn export_bundle_zip_with_selection(
    app: tauri::AppHandle,
    batch_id: String,
    selection: ExportBundleSelection,
    _embed_files: Option<bool>,
) -> Result<String, String> {
    let batch_dir = batch_dir(&app, &batch_id).map_err(err_to_string)?;
    let batch: BatchSummary = read_batch(&batch_dir).map_err(err_to_string)?;
    let batch = apply_bundle_selection(&batch, selection).map_err(err_to_string)?;

    if batch.zips.is_empty() {
        return Err("æœªé€‰æ‹©ä»»ä½•ZIPç”¨äºå¯¼å‡º".to_string());
    }

    let now = OffsetDateTime::now_utc();
    // ä¿®æ”¹ï¼šç›´æ¥ä¿å­˜ä¸º.docxæ–‡ä»¶ï¼Œä¸å†å‹ç¼©ä¸º.zip
    let out = prompt_save_path(default_export_bundle_name(now), "docx", "Wordæ–‡æ¡£")?;

    // å§‹ç»ˆä½¿ç”¨æ–‡ä»¶åµŒå…¥åŠŸèƒ½
    println!("=== å¼€å§‹æ–‡ä»¶åµŒå…¥å¯¼å‡º ===");
    println!("1. æ”¶é›†éœ€è¦åµŒå…¥çš„æ–‡ä»¶...");
    let (docx, embedded_files) = build_enhanced_summary_docx(&batch, true).map_err(err_to_string)?;

    println!("2. ç”ŸæˆåŸºç¡€Wordæ–‡æ¡£...");
    println!("3. å¼€å§‹åµŒå…¥æ–‡ä»¶åˆ°Wordæ–‡æ¡£...");
    let docx_bytes = build_docx_with_embeddings(docx, &embedded_files).map_err(err_to_string)?;

    // ç›´æ¥ä¿å­˜docxæ–‡ä»¶ï¼Œä¸å†åˆ›å»ºzipåŒ…
    println!("4. ä¿å­˜Wordæ–‡æ¡£åˆ°: {}", out.display());
    fs::write(&out, docx_bytes).map_err(err_to_string)?;

    println!("âœ“ Wordæ–‡æ¡£å¯¼å‡ºå®Œæˆï¼");
    println!("ç”Ÿæˆçš„Wordæ–‡æ¡£åŒ…å« {} ä¸ªåµŒå…¥æ–‡ä»¶", embedded_files.len());
    println!("æç¤º: æ‰€æœ‰é™„ä»¶æ–‡ä»¶å·²å®Œæ•´åµŒå…¥åˆ°Wordæ–‡æ¡£ä¸­");

    Ok(out.to_string_lossy().to_string())
}

fn read_batch(batch_dir: &Path) -> Result<BatchSummary> {
    let path = batch_dir.join("batch.json");
    let data = fs::read(&path).with_context(|| format!("è¯»å–æ‰¹æ¬¡ä¿¡æ¯å¤±è´¥: {}", path.display()))?;
    let batch: BatchSummary = serde_json::from_slice(&data)?;
    Ok(batch)
}

fn apply_bundle_selection(batch: &BatchSummary, selection: ExportBundleSelection) -> Result<BatchSummary> {
    let mut out = Vec::new();

    for z in &batch.zips {
        let sel = selection.zips.iter().find(|s| s.zip_id == z.id);
        let Some(sel) = sel else { continue };
        if !sel.include {
            continue;
        }

        let mut z2 = z.clone();
        z2.include_original_zip = sel.include_original_zip;
        let mut selected_videos = Vec::new();
        for &idx in &sel.selected_video_indices {
            if let Some(p) = z.video_files.get(idx) {
                selected_videos.push(p.clone());
            }
        }
        z2.video_files = selected_videos;

        let mut selected_images = Vec::new();
        for &idx in &sel.selected_image_indices {
            if let Some(p) = z.image_files.get(idx) {
                selected_images.push(p.clone());
            }
        }
        z2.image_files = selected_images;

        let mut selected_pdfs = Vec::new();
        for &idx in &sel.selected_pdf_indices {
            if let Some(p) = z.pdf_files.get(idx) {
                selected_pdfs.push(p.clone());
            }
        }
        z2.pdf_files = selected_pdfs;

        let mut selected_pdf_screens = Vec::new();
        for &idx in &sel.selected_pdf_page_screenshot_indices {
            if let Some(p) = z.pdf_page_screenshot_files.get(idx) {
                selected_pdf_screens.push(p.clone());
            }
        }
        z2.pdf_page_screenshot_files = selected_pdf_screens;

        let mut selected_excels = Vec::new();
        for &idx in &sel.selected_excel_indices {
            if let Some(p) = z.excel_files.get(idx) {
                selected_excels.push(p.clone());
            }
        }
        z2.excel_files = selected_excels;

        out.push(z2);
    }

    // æŒ‰ä¸‹å‘æ—¶é—´æ’åº
    sort_zips_by_issued_at(&mut out);

    Ok(BatchSummary {
        batch_id: batch.batch_id.clone(),
        created_at: batch.created_at,
        zips: out,
    })
}

#[derive(Debug, Clone)]
struct ZipScan {
    docx_entry: String,
    video_entries: Vec<usize>,  // å­˜å‚¨ZIPä¸­çš„ç´¢å¼•
    image_entries: Vec<usize>,
    pdf_entries: Vec<usize>,
    excel_entries: Vec<usize>,
    has_sample: bool,
}

/// è§£ç ZIPæ–‡ä»¶åï¼ˆå¤„ç†ä¸­æ–‡ä¹±ç ï¼‰
/// Windowsåˆ›å»ºçš„ZIPæ–‡ä»¶é€šå¸¸ä½¿ç”¨GBKç¼–ç ï¼Œéœ€è¦æ­£ç¡®è§£ç 
fn decode_zip_filename(name_bytes: &[u8]) -> String {
    // é¦–å…ˆå°è¯•UTF-8è§£ç 
    if let Ok(utf8_name) = std::str::from_utf8(name_bytes) {
        // æ£€æŸ¥æ˜¯å¦åŒ…å«ä¹±ç å­—ç¬¦ï¼ˆå¦‚â–¡ã€ï¿½ç­‰ï¼‰
        if !utf8_name.chars().any(|c| c == '\u{FFFD}' || c == 'â–¡') {
            return utf8_name.to_string();
        }
    }

    // UTF-8å¤±è´¥æˆ–æœ‰ä¹±ç ï¼Œå°è¯•GBKè§£ç 
    let (decoded, _encoding, had_errors) = GBK.decode(name_bytes);
    if !had_errors {
        return decoded.to_string();
    }

    // éƒ½å¤±è´¥äº†ï¼Œä½¿ç”¨UTF-8å¹¶æ›¿æ¢æ— æ•ˆå­—ç¬¦
    String::from_utf8_lossy(name_bytes).to_string()
}

fn scan_zip(zip_path: &Path) -> Result<ZipScan> {
    let f = fs::File::open(zip_path)?;
    let mut zip = ZipArchive::new(f)?;

    let mut docx_entry: Option<String> = None;
    let mut has_sample = false;
    let mut video_entries = Vec::new();
    let mut image_entries = Vec::new();
    let mut pdf_entries = Vec::new();
    let mut excel_entries = Vec::new();

    for i in 0..zip.len() {
        let file = zip.by_index(i)?;
        // ä¿å­˜åŸå§‹æ–‡ä»¶åï¼ˆç”¨äºåç»­ä»ZIPä¸­è¯»å–ï¼‰
        let name = file.name().to_string();
        let lower = name.to_ascii_lowercase();

        if lower.ends_with(".docx") {
            if docx_entry.is_some() {
                return Err(anyhow!("ZIPå†…å‘ç°å¤šä¸ªdocxï¼Œä¸ç¬¦åˆå‰æ"));
            }
            docx_entry = Some(name);
            continue;
        }

        if lower.ends_with("/") || lower.ends_with(".ds_store") {
            continue;
        }

        // Wordä¹‹å¤–éƒ½ç®—æ ·æœ¬
        has_sample = true;

        if lower.ends_with(".mp4") {
            video_entries.push(i);  // ä¿å­˜ç´¢å¼•
        } else if lower.ends_with(".pdf") {
            pdf_entries.push(i);
        } else if lower.ends_with(".png")
            || lower.ends_with(".jpg")
            || lower.ends_with(".jpeg")
            || lower.ends_with(".gif")
        {
            image_entries.push(i);
        } else if lower.ends_with(".xlsx") || lower.ends_with(".xls") {
            excel_entries.push(i);
        }
    }

    Ok(ZipScan {
        docx_entry: docx_entry.ok_or_else(|| anyhow!("ZIPå†…æœªæ‰¾åˆ°docx"))?,
        video_entries,
        image_entries,
        pdf_entries,
        excel_entries,
        has_sample,
    })
}

fn extract_word_and_videos(zip_path: &Path, scan: &ZipScan) -> Result<(WordFields, Vec<String>)> {
    let f = fs::File::open(zip_path)?;
    let mut zip = ZipArchive::new(f)?;

    let docx_bytes = {
        let mut file = zip.by_name(&scan.docx_entry)?;
        let mut buf = Vec::new();
        file.read_to_end(&mut buf)?;
        buf
    };
    let fields = extract_fields_from_docx(&docx_bytes)?;

    // è¿”å›ç©ºçš„ video_entriesï¼Œå› ä¸ºç°åœ¨ä½¿ç”¨ç´¢å¼•è€Œä¸æ˜¯æ–‡ä»¶å
    // å®é™…çš„æ–‡ä»¶ä¿¡æ¯åœ¨ extract_preview_files ä¸­å¤„ç†
    Ok((fields, vec![]))
}

fn extract_preview_files(
    batch_dir: &Path,
    zip_id: &str,
    zip_path: &Path,
    scan: &ZipScan,
    summary: &mut ZipSummary,
) -> Result<()> {
    let root = batch_dir.join("zips").join(zip_id).join("extracted");
    summary.extracted_dir = root.to_string_lossy().to_string();
    let videos_dir = root.join("videos");
    let images_dir = root.join("images");
    let pdf_dir = root.join("pdf");
    let excel_dir = root.join("excel");
    fs::create_dir_all(&videos_dir)?;
    fs::create_dir_all(&images_dir)?;
    fs::create_dir_all(&pdf_dir)?;
    fs::create_dir_all(&excel_dir)?;

    let f = fs::File::open(zip_path)?;
    let mut zip = ZipArchive::new(f)?;

    for &index in &scan.video_entries {
        let mut file = zip.by_index(index)?;
        let name = decode_zip_filename(file.name_raw());  // æ­£ç¡®è§£ç æ–‡ä»¶å
        let basename = safe_basename(&name);
        let out = unique_path(&videos_dir, &basename);
        let mut buf = Vec::new();
        file.read_to_end(&mut buf)?;
        fs::write(&out, buf)?;
        summary.video_files.push(out.to_string_lossy().to_string());
    }

    for &index in &scan.image_entries {
        let mut file = zip.by_index(index)?;
        let name = decode_zip_filename(file.name_raw());
        let basename = safe_basename(&name);
        let out = unique_path(&images_dir, &basename);
        let mut buf = Vec::new();
        file.read_to_end(&mut buf)?;
        fs::write(&out, buf)?;
        summary.image_files.push(out.to_string_lossy().to_string());
    }

    for &index in &scan.pdf_entries {
        let mut file = zip.by_index(index)?;
        let name = decode_zip_filename(file.name_raw());
        let basename = safe_basename(&name);
        let out = unique_path(&pdf_dir, &basename);
        let mut buf = Vec::new();
        file.read_to_end(&mut buf)?;
        fs::write(&out, buf)?;
        summary.pdf_files.push(out.to_string_lossy().to_string());
    }

    for &index in &scan.excel_entries {
        let mut file = zip.by_index(index)?;
        let name = decode_zip_filename(file.name_raw());
        let basename = safe_basename(&name);
        let out = unique_path(&excel_dir, &basename);
        let mut buf = Vec::new();
        file.read_to_end(&mut buf)?;
        fs::write(&out, buf)?;
        summary.excel_files.push(out.to_string_lossy().to_string());
    }

    Ok(())
}

fn unique_path(dir: &Path, file_name: &str) -> PathBuf {
    let base = Path::new(file_name)
        .file_stem()
        .and_then(|s| s.to_str())
        .unwrap_or("file");
    let ext = Path::new(file_name).extension().and_then(|s| s.to_str());

    let mut n = 0usize;
    loop {
        let candidate = if n == 0 {
            match ext {
                Some(ext) => dir.join(format!("{base}.{ext}")),
                None => dir.join(base),
            }
        } else {
            match ext {
                Some(ext) => dir.join(format!("{base}_{n}.{ext}")),
                None => dir.join(format!("{base}_{n}")),
            }
        };
        if !candidate.exists() {
            return candidate;
        }
        n += 1;
    }
}

fn extract_fields_from_docx(docx_bytes: &[u8]) -> Result<WordFields> {
    let cursor = Cursor::new(docx_bytes);
    let mut zip = ZipArchive::new(cursor)?;
    let mut document_xml = zip
        .by_name("word/document.xml")
        .context("docxç¼ºå°‘word/document.xml")?;
    let mut xml = String::new();
    document_xml.read_to_string(&mut xml)?;

    let text = extract_paragraph_texts(&xml)?;

    // å¤„ç†å­—æ®µæå–ï¼Œç‰¹åˆ«å¤„ç†æŒ‡ä»¤å†…å®¹çš„å¤šè¡Œæƒ…å†µ
    let fields = extract_all_fields(&text)?;

    fn first_nonempty(values: Option<&Vec<String>>) -> String {
        let Some(values) = values else { return String::new() };
        for v in values {
            let t = v.trim();
            if !t.is_empty() {
                return t.to_string();
            }
        }
        String::new()
    }

    // å¯¹äºæŒ‡ä»¤å†…å®¹ï¼Œç›´æ¥ä½¿ç”¨æå–çš„å®Œæ•´å†…å®¹ï¼Œä¸å†é€‰æ‹©"æœ€ä½³"
    fn get_instruction_content(values: Option<&Vec<String>>) -> String {
        let Some(values) = values else { return String::new() };
        for v in values {
            let t = v.trim();
            if !t.is_empty() && t != "åºå·" {
                return t.to_string();
            }
        }
        String::new()
    }

    Ok(WordFields {
        instruction_no: first_nonempty(fields.get("æŒ‡ä»¤ç¼–å·")),
        title: first_nonempty(fields.get("æŒ‡ä»¤æ ‡é¢˜")),
        issued_at: first_nonempty(fields.get("ä¸‹å‘æ—¶é—´")),
        content: get_instruction_content(fields.get("æŒ‡ä»¤å†…å®¹")),
    })
}

// æ£€æŸ¥æ˜¯å¦æ˜¯è¡¨æ ¼è¡¨å¤´æˆ–è¡¨æ ¼å†…å®¹
fn is_table_header_or_content(line: &str) -> bool {
    let trimmed = line.trim();

    // å¸¸è§çš„è¡¨æ ¼è¡¨å¤´æ¨¡å¼
    let table_headers = [
        "æ ‡é¢˜", "é“¾æ¥", "ç½‘ç«™", "å±åœ°", "å¤„ç½®æ–¹å¼", "åºå·", "æ—¶é—´", "å†…å®¹", "ç±»å‹",
        "ç¼–å·", "åç§°", "åœ°å€", "æ¥æº", "çŠ¶æ€", "å¤‡æ³¨", "æ“ä½œ", "è¯¦æƒ…",
        "é“¾æ¥åœ°å€", "ç½‘ç«™åç§°", "å¤„ç†æ–¹å¼", "å¤„ç†ç»“æœ", "å¤„ç†æ—¶é—´"
    ];

    // æ£€æŸ¥æ˜¯å¦åŒ…å«è¡¨æ ¼è¡¨å¤´å…³é”®è¯
    for header in &table_headers {
        if trimmed.contains(header) && trimmed.len() <= 20 {
            return true;
        }
    }

    // æ£€æŸ¥æ˜¯å¦æ˜¯çº¯æ•°å­—æˆ–ç¼–å·ï¼ˆè¡¨æ ¼ä¸­çš„å¸¸è§å†…å®¹ï¼‰
    if trimmed.chars().all(|c| c.is_ascii_digit() || c == '.' || c == 'ã€') {
        return true;
    }

    // æ£€æŸ¥æ˜¯å¦æ˜¯URLé“¾æ¥ï¼ˆè¡¨æ ¼ä¸­å¸¸è§ï¼‰
    if trimmed.starts_with("http://") || trimmed.starts_with("https://") || trimmed.starts_with("www.") {
        return true;
    }

    // æ£€æŸ¥æ˜¯å¦åŒ…å«å¤§é‡åˆ†éš”ç¬¦ï¼ˆè¡¨æ ¼ç‰¹å¾ï¼‰
    let tab_count = trimmed.matches('\t').count();
    let space_count = trimmed.matches("  ").count();
    if tab_count >= 2 || space_count >= 3 {
        return true;
    }

    false
}

// æå–æ‰€æœ‰å­—æ®µï¼Œç‰¹åˆ«å¤„ç†æŒ‡ä»¤å†…å®¹çš„å¤šè¡Œæƒ…å†µ
fn extract_all_fields(text: &str) -> Result<std::collections::BTreeMap<String, Vec<String>>> {
    let mut map: std::collections::BTreeMap<String, Vec<String>> = std::collections::BTreeMap::new();
    let lines: Vec<&str> = text.lines().collect();

    let mut i = 0;
    while i < lines.len() {
        let line = lines[i].trim();

        // æ£€æŸ¥æ˜¯å¦æ˜¯å­—æ®µè¡Œ
        if let Some(cap) = RE_FIELD.captures(line) {
            let key = cap.get(1).unwrap().as_str().to_string();
            let mut value = cap.name("v").unwrap().as_str().trim().to_string();

            // å¦‚æœæ˜¯æŒ‡ä»¤å†…å®¹ï¼Œéœ€è¦æ”¶é›†å¤šè¡Œå†…å®¹
            if key == "æŒ‡ä»¤å†…å®¹" {
                // æ”¶é›†åç»­éå­—æ®µè¡Œï¼Œç›´åˆ°é‡åˆ°ä¸‹ä¸€ä¸ªå­—æ®µæˆ–è¡¨æ ¼
                i += 1;
                let mut content_lines = Vec::new();
                while i < lines.len() {
                    let next_line = lines[i].trim();

                    // å¦‚æœä¸‹ä¸€ä¸ªå­—æ®µå¼€å§‹ï¼Œåœæ­¢æ”¶é›†
                    if RE_FIELD.is_match(next_line) {
                        break;
                    }

                    // å¦‚æœé‡åˆ°ç©ºè¡Œï¼Œç»§ç»­æ£€æŸ¥ä¸‹ä¸€è¡Œï¼ˆç©ºè¡Œå¯èƒ½æ˜¯æ®µè½åˆ†éš”ï¼‰
                    if next_line.is_empty() {
                        i += 1;
                        continue;
                    }

                    // å¦‚æœæ˜¯è¡¨æ ¼è¡¨å¤´æˆ–è¡¨æ ¼å†…å®¹ï¼Œåœæ­¢æ”¶é›†æŒ‡ä»¤å†…å®¹
                    if is_table_header_or_content(next_line) {
                        break;
                    }

                    // è¿‡æ»¤æ‰ä¸€äº›æ˜æ˜¾çš„éå†…å®¹è¡Œ
                    if next_line != "åºå·" && next_line != "æŒ‡ä»¤ç¼–å·" && next_line != "æŒ‡ä»¤æ ‡é¢˜" && next_line != "ä¸‹å‘æ—¶é—´" {
                        // æ£€æŸ¥è¡Œé•¿åº¦ï¼Œè¿‡çŸ­çš„è¡Œå¯èƒ½ä¸æ˜¯å†…å®¹
                        if next_line.len() > 3 {
                            content_lines.push(next_line);
                        }
                    }
                    i += 1;
                }

                // ä¿ç•™åŸå§‹æ ¼å¼çš„å¤šè¡Œå†…å®¹
                if !content_lines.is_empty() {
                    let multi_line_content = content_lines.join("\n");
                    let cleaned_content = normalize_instruction_content_with_format(&format!("{}\n{}", value, multi_line_content));
                    value = cleaned_content;
                }
                i -= 1; // å›é€€ä¸€è¡Œï¼Œå› ä¸ºå¤–å±‚å¾ªç¯ä¼šå†æ¬¡é€’å¢
            } else {
                // å¯¹äºå…¶ä»–å­—æ®µï¼Œåº”ç”¨ç®€å•çš„æ¸…ç†
                value = normalize_text(&value);
            }

            map.entry(key).or_default().push(value);
        }
        i += 1;
    }

    Ok(map)
}

fn extract_paragraph_texts(document_xml: &str) -> Result<String> {
    let mut reader = XmlReader::from_str(document_xml);
    reader.config_mut().trim_text(false);
    let mut buf = Vec::new();
    let mut current = String::new();
    let mut out = String::new();
    let mut in_paragraph = false;

    loop {
        match reader.read_event_into(&mut buf) {
            Ok(Event::Start(e)) => {
                if e.name().as_ref() == b"w:p" {
                    in_paragraph = true;
                    current.clear();
                }
            }
            Ok(Event::Empty(e)) => {
                if in_paragraph && e.name().as_ref() == b"w:br" {
                    current.push('\n');
                }
            }
            Ok(Event::End(e)) => {
                if e.name().as_ref() == b"w:p" {
                    in_paragraph = false;
                    let line = normalize_text(&current);
                    if !line.trim().is_empty() {
                        out.push_str(line.trim_end());
                        out.push('\n');
                    }
                }
            }
            Ok(Event::Text(e)) => {
                if in_paragraph {
                    current.push_str(&e.unescape()?.to_string());
                }
            }
            Ok(Event::Eof) => break,
            Err(err) => return Err(anyhow!("XMLè§£æé”™è¯¯: {:?}", err)),
            _ => {}
        }
        buf.clear();
    }

    Ok(out)
}

fn normalize_text(s: &str) -> String {
    s.replace('\u{00A0}', " ")
        .replace('\u{3000}', " ")
        .replace('ï¼š', ":")
}

// ä¸“é—¨ç”¨äºå¤„ç†æŒ‡ä»¤å†…å®¹çš„å‡½æ•°ï¼Œä¿ç•™æ ‡ç‚¹ç¬¦å·å’Œæ ¼å¼

// ä¸“é—¨ç”¨äºå¤„ç†æŒ‡ä»¤å†…å®¹çš„å‡½æ•°ï¼Œä¿ç•™åŸå§‹æ ¼å¼ï¼ˆæ¢è¡Œã€æ®µè½ç­‰ï¼‰
fn normalize_instruction_content_with_format(s: &str) -> String {
    let mut result = String::new();
    let mut lines = Vec::new();

    // æŒ‰è¡Œåˆ†å‰²å†…å®¹ï¼Œä¿ç•™ç©ºè¡Œï¼ˆæ®µè½åˆ†éš”ï¼‰
    for line in s.lines() {
        let trimmed = line.trim_end();  // åªåˆ é™¤è¡Œå°¾ç©ºç™½ï¼Œä¿ç•™æ ‡ç‚¹
        lines.push(trimmed);
    }

    // é‡æ–°ç»„åˆå†…å®¹ï¼Œä¿ç•™åŸå§‹æ¢è¡Œç»“æ„
    for (i, line) in lines.iter().enumerate() {
        if i > 0 {
            // æ£€æŸ¥æ˜¯å¦éœ€è¦åœ¨æ¢è¡Œå‰æ·»åŠ ç©ºæ ¼
            let prev_line = lines[i-1];
            let current_line = *line;

            // å¦‚æœå‰ä¸€è¡Œä»¥æ ‡ç‚¹ç»“å°¾ï¼Œä¸”å½“å‰è¡Œä¸æ˜¯ç©ºè¡Œï¼Œä¿ç•™æ¢è¡Œ
            if !current_line.is_empty() &&
               (prev_line.ends_with('ã€‚') || prev_line.ends_with('ï¼') || prev_line.ends_with('ï¼Ÿ') ||
                prev_line.ends_with('.') || prev_line.ends_with('!') || prev_line.ends_with('?')) {
                // ä¿ç•™æ¢è¡Œ
                result.push('\n');
            } else if !current_line.is_empty() && !prev_line.is_empty() {
                // å¦‚æœéƒ½ä¸æ˜¯ç©ºè¡Œï¼Œä¸”å‰ä¸€è¡Œä¸æ˜¯å¥å·ç­‰ç»“æŸï¼Œæ·»åŠ æ¢è¡Œ
                result.push('\n');
            } else {
                // å¦‚æœå½“å‰è¡Œæ˜¯ç©ºè¡Œï¼Œæ·»åŠ é¢å¤–çš„æ¢è¡Œï¼ˆæ®µè½åˆ†éš”ï¼‰
                result.push('\n');
            }
        }

        // æ›¿æ¢ç‰¹æ®Šç©ºç™½å­—ç¬¦ï¼Œä½†ä¿ç•™æ ¼å¼
        let cleaned = line.replace('\u{00A0}', " ")
                         .replace('\u{3000}', " ")
                         .replace('ï¼š', ":");
        result.push_str(&cleaned);
    }

    // æ¸…ç†å¼€å¤´å’Œç»“å°¾çš„ç©ºç™½å­—ç¬¦ï¼Œä½†ä¿ç•™ä¸­é—´çš„æ¢è¡Œ
    result.trim_matches('\n').trim_matches('\r').to_string()
}

// è§£æä¸‹å‘æ—¶é—´å­—ç¬¦ä¸²ä¸º OffsetDateTimeï¼Œæ”¯æŒå¤šç§æ ¼å¼
fn parse_issued_at(date_str: &str) -> Result<OffsetDateTime> {
    let trimmed = date_str.trim();
    if trimmed.is_empty() {
        // å¦‚æœæ—¶é—´ä¸ºç©ºï¼Œè¿”å›ä¸€ä¸ªå¾ˆæ—©çš„æ—¶é—´ä½œä¸ºé»˜è®¤å€¼
        return Ok(OffsetDateTime::UNIX_EPOCH);
    }

    // å°è¯•å®Œæ•´çš„æ—¶é—´æˆ³æ ¼å¼ YYYY-MM-DD HH:MM:SS
    if trimmed.len() >= 19 {
        let date_part = &trimmed[0..10];
        let time_part = &trimmed[11..19];

        if date_part.chars().nth(4) == Some('-') && date_part.chars().nth(7) == Some('-') &&
           time_part.chars().nth(2) == Some(':') && time_part.chars().nth(5) == Some(':') {

            // è§£ææ—¥æœŸéƒ¨åˆ†
            if let (Ok(year), Ok(month_u8), Ok(day)) = (
                date_part[0..4].parse::<i32>(),
                date_part[5..7].parse::<u8>(),
                date_part[8..10].parse::<u8>()
            ) {
                // è§£ææ—¶é—´éƒ¨åˆ†
                if let (Ok(hour), Ok(minute), Ok(second)) = (
                    time_part[0..2].parse::<u8>(),
                    time_part[3..5].parse::<u8>(),
                    time_part[6..8].parse::<u8>()
                ) {
                    // è½¬æ¢æœˆä»½ç±»å‹
                    if let Ok(month) = time::Month::try_from(month_u8) {
                        if let (Ok(date), Ok(time)) = (
                            time::Date::from_calendar_date(year, month, day),
                            time::Time::from_hms(hour, minute, second)
                        ) {
                            return Ok(time::PrimitiveDateTime::new(date, time).assume_utc());
                        }
                    }
                }
            }
        }
    }

    // å°è¯•å¸¦æ—¶é—´çš„ YYYY-MM-DD HH:MM æ ¼å¼
    if trimmed.len() >= 16 && trimmed.len() < 19 {
        let date_part = &trimmed[0..10];
        let time_part = &trimmed[11..16];

        if date_part.chars().nth(4) == Some('-') && date_part.chars().nth(7) == Some('-') &&
           time_part.chars().nth(2) == Some(':') {

            // è§£ææ—¥æœŸéƒ¨åˆ†
            if let (Ok(year), Ok(month_u8), Ok(day)) = (
                date_part[0..4].parse::<i32>(),
                date_part[5..7].parse::<u8>(),
                date_part[8..10].parse::<u8>()
            ) {
                // è§£ææ—¶é—´éƒ¨åˆ†
                if let (Ok(hour), Ok(minute)) = (
                    time_part[0..2].parse::<u8>(),
                    time_part[3..5].parse::<u8>()
                ) {
                    // è½¬æ¢æœˆä»½ç±»å‹
                    if let Ok(month) = time::Month::try_from(month_u8) {
                        if let (Ok(date), Ok(time)) = (
                            time::Date::from_calendar_date(year, month, day),
                            time::Time::from_hms(hour, minute, 0)
                        ) {
                            return Ok(time::PrimitiveDateTime::new(date, time).assume_utc());
                        }
                    }
                }
            }
        }
    }

    // ç®€å•çš„è§£æç­–ç•¥ï¼šå°è¯•æ•°å­—æ ¼å¼
    if let Ok(num) = trimmed.parse::<i64>() {
        if num >= 10000101 && num <= 99991231 {
            let year = (num / 10000) as i32;
            let month = ((num % 10000) / 100) as u8;
            let day = (num % 100) as u8;

            if month >= 1 && month <= 12 && day >= 1 && day <= 31 {
                // ä½¿ç”¨time 0.3å…¼å®¹çš„API
                if let Ok(month) = time::Month::try_from(month) {
                    if let Ok(date) = time::Date::from_calendar_date(year, month, day) {
                        return Ok(time::PrimitiveDateTime::new(date, time::Time::MIDNIGHT).assume_utc());
                    }
                }
            }
        }
    }

    // å°è¯•æ ‡å‡†æ ¼å¼ YYYY-MM-DD
    if trimmed.len() >= 10 && trimmed.chars().nth(4) == Some('-') && trimmed.chars().nth(7) == Some('-') {
        if let Ok(year) = trimmed[0..4].parse::<i32>() {
            if let Ok(month) = trimmed[5..7].parse::<u8>() {
                if let Ok(day) = trimmed[8..10].parse::<u8>() {
                    if let Ok(month) = time::Month::try_from(month) {
                        if let Ok(date) = time::Date::from_calendar_date(year, month, day) {
                            return Ok(time::PrimitiveDateTime::new(date, time::Time::MIDNIGHT).assume_utc());
                        }
                    }
                }
            }
        }
    }

    // å¦‚æœéƒ½æ— æ³•è§£æï¼Œè¿”å›å½“å‰æ—¶é—´
    Ok(OffsetDateTime::now_utc())
}

// å¯¹ ZipSummary åˆ—è¡¨æŒ‰ä¸‹å‘æ—¶é—´æ’åº
fn sort_zips_by_issued_at(zips: &mut Vec<ZipSummary>) {
    zips.sort_by(|a, b| {
        let time_a = parse_issued_at(&a.word.issued_at).unwrap_or_else(|_| OffsetDateTime::UNIX_EPOCH);
        let time_b = parse_issued_at(&b.word.issued_at).unwrap_or_else(|_| OffsetDateTime::UNIX_EPOCH);
        time_a.cmp(&time_b)
    });
}

fn build_summary_docx(batch: &BatchSummary) -> Result<Vec<u8>> {
    let mut docx = Docx::new();
    docx = docx.add_paragraph(
        Paragraph::new().add_run(Run::new().add_text("æ±‡æ€»æ–‡æ¡£").bold()),
    );

    for z in &batch.zips {
        let zip_folder = format!("attachments/{}/", z.id);
        docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_text(format!(
            "æŒ‡ä»¤ç¼–å·:  {}",
            z.word.instruction_no
        ))));
        docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_text(format!(
            "æŒ‡ä»¤æ ‡é¢˜:  {}",
            z.word.title
        ))));
        docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_text(format!(
            "ä¸‹å‘æ—¶é—´:  {}",
            z.word.issued_at
        ))));
        if !z.word.content.trim().is_empty() {
            docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_text("æŒ‡ä»¤å†…å®¹:")));
            // å°†æŒ‡ä»¤å†…å®¹æŒ‰æ¢è¡Œç¬¦åˆ†å‰²ï¼Œåˆ›å»ºå¤šä¸ªæ®µè½
            for line in z.word.content.lines() {
                let trimmed_line = line.trim();
                if !trimmed_line.is_empty() {
                    docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_text(trimmed_line)));
                } else {
                    // ç©ºè¡Œåˆ›å»ºç©ºæ®µè½ï¼ˆæ®µè½é—´è·ï¼‰
                    docx = docx.add_paragraph(Paragraph::new());
                }
            }
        }

        // ç›´æ¥æ˜¾ç¤ºå›¾ç‰‡ï¼Œåˆ é™¤"å›¾ç‰‡"æ ‡é¢˜
        for img_path in &z.image_files {
            let bytes = fs::read(img_path)
                .with_context(|| format!("è¯»å–å›¾ç‰‡å¤±è´¥: {}", img_path))?;
            let pic = Pic::new(&bytes);
            docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_image(pic)));
        }

        // ç›´æ¥æ˜¾ç¤ºPDFå›¾ç‰‡ï¼Œåˆ é™¤"PDFé¡µé¢å›¾ç‰‡:"æ ‡é¢˜
        
        // ç›´æ¥æ˜¾ç¤ºPDFæˆªå›¾ï¼Œåˆ é™¤"PDFé¡µé¢æˆªå›¾:"æ ‡é¢˜
        for img_path in &z.pdf_page_screenshot_files {
            let bytes = fs::read(img_path)
                .with_context(|| format!("è¯»å–PDFé¡µé¢æˆªå›¾å¤±è´¥: {}", img_path))?;
            let pic = Pic::new(&bytes);
            docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_image(pic)));
        }

        docx = docx.add_paragraph(
            Paragraph::new().add_run(Run::new().add_text("é™„ä»¶æ¸…å•:").bold()),
        );

        // ä»…æä¾›â€œæœ¬ZIPé™„ä»¶æ–‡ä»¶å¤¹â€é“¾æ¥
        let folder_link = Hyperlink::new(&zip_folder, HyperlinkType::External)
            .add_run(Run::new().add_text(zip_folder.clone()).style("Hyperlink"));
        docx = docx.add_paragraph(
            Paragraph::new()
                .add_run(Run::new().add_text("é™„ä»¶ç›®å½•ï¼š"))
                .add_hyperlink(folder_link),
        );

        for video in &z.video_files {
            docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_text(format!(
                "- {}",
                safe_basename(video)
            ))));
        }
        if z.include_original_zip {
            docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_text(format!(
                "- {}",
                z.filename
            ))));
        }
        if z.video_files.is_empty() && !z.include_original_zip {
            docx = docx
                .add_paragraph(Paragraph::new().add_run(Run::new().add_text("- ï¼ˆæ— ï¼‰")));
        }
        docx = docx.add_paragraph(Paragraph::new().add_run(Run::new().add_text("â€” â€” â€”")));
    }

    let mut out = Cursor::new(Vec::<u8>::new());
    docx.build()
        .pack(&mut out)
        .map_err(|e| anyhow!("docxç”Ÿæˆå¤±è´¥: {e:?}"))?;
    Ok(out.into_inner())
}

fn build_bundle_zip_bytes(batch: &BatchSummary, docx_bytes: &[u8]) -> Result<Vec<u8>> {
    let file_options = FileOptions::default();
    let dir_options = FileOptions::default();

    let mut out = Cursor::new(Vec::<u8>::new());
    {
        let mut writer = ZipWriter::new(&mut out);

        writer.start_file("æ±‡æ€»æ–‡æ¡£.docx", file_options)?;
        writer.write_all(docx_bytes)?;

        writer.add_directory("attachments/", dir_options)?;

        for z in &batch.zips {
            let zip_dir = format!("attachments/{}/", z.id);
            writer.add_directory(&zip_dir, dir_options)?;

            let zip_path = if !z.stored_path.trim().is_empty() {
                PathBuf::from(&z.stored_path)
            } else {
                PathBuf::from(&z.source_path)
            };
            if z.include_original_zip {
                let zip_bytes = fs::read(&zip_path)
                    .with_context(|| format!("è¯»å–ZIPå¤±è´¥: {}", zip_path.display()))?;
                writer.start_file(format!("{zip_dir}{}", z.filename), file_options)?;
                writer.write_all(&zip_bytes)?;
            }

            for video_path in &z.video_files {
                let bytes = fs::read(video_path)
                    .with_context(|| format!("è¯»å–è§†é¢‘å¤±è´¥: {}", video_path))?;
                writer.start_file(
                    format!("{zip_dir}{}", safe_basename(video_path)),
                    file_options,
                )?;
                writer.write_all(&bytes)?;
            }

            for pdf_path in &z.pdf_files {
                let bytes = fs::read(pdf_path)
                    .with_context(|| format!("è¯»å–PDFå¤±è´¥: {}", pdf_path))?;
                writer.start_file(format!("{zip_dir}{}", safe_basename(pdf_path)), file_options)?;
                writer.write_all(&bytes)?;
            }
        }

        writer.finish()?;
    } // writer åœ¨è¿™é‡Œè¢« dropï¼Œé‡Šæ”¾å¯¹ out çš„å€Ÿç”¨

    Ok(out.into_inner())
}

fn safe_basename(name: &str) -> String {
    let n = name.replace('\\', "/");
    n.rsplit('/').next().unwrap_or(&n).to_string()
}

fn err_to_string<E: std::fmt::Display>(e: E) -> String {
    e.to_string()
}

#[tauri::command]
fn open_path(path: String) -> Result<(), String> {
    let p = PathBuf::from(path);
    if !p.exists() {
        return Err("è·¯å¾„ä¸å­˜åœ¨".to_string());
    }
    open_in_os(&p).map_err(err_to_string)?;
    Ok(())
}

fn open_in_os(path: &Path) -> Result<()> {
    #[cfg(target_os = "macos")]
    {
        let status = Command::new("open").arg(path).status()?;
        if !status.success() {
            return Err(anyhow!("open è¿”å›é0çŠ¶æ€ç "));
        }
        return Ok(());
    }

    #[cfg(target_os = "windows")]
    {
        // Windowsä¸Šä½¿ç”¨exploreræ‰“å¼€æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹
        // å¦‚æœæ˜¯æ–‡ä»¶ï¼Œä½¿ç”¨ /select å‚æ•°åœ¨èµ„æºç®¡ç†å™¨ä¸­é€‰ä¸­å®ƒ
        // å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œç›´æ¥æ‰“å¼€
        if path.is_file() {
            // /select å‚æ•°æ ¼å¼: explorer /select,"C:\path\to\file"
            let path_str = path.to_str().unwrap_or("");
            let select_arg = format!("/select,{}", path_str);
            let status = Command::new("explorer")
                .arg(select_arg)
                .status()?;
            if !status.success() {
                return Err(anyhow!("explorer è¿”å›é0çŠ¶æ€ç "));
            }
        } else {
            let status = Command::new("explorer")
                .arg(path)
                .status()?;
            if !status.success() {
                return Err(anyhow!("explorer è¿”å›é0çŠ¶æ€ç "));
            }
        }
        return Ok(());
    }

    #[cfg(all(not(target_os = "macos"), not(target_os = "windows")))]
    {
        let status = Command::new("xdg-open").arg(path).status()?;
        if !status.success() {
            return Err(anyhow!("xdg-open è¿”å›é0çŠ¶æ€ç "));
        }
        return Ok(());
    }
}

#[tauri::command]
fn get_preview_image_data(
    app: tauri::AppHandle,
    batch_id: String,
    zip_id: String,
    index: usize,
) -> Result<String, String> {
    let batch_dir = batch_dir(&app, &batch_id).map_err(err_to_string)?;
    let batch: BatchSummary = read_batch(&batch_dir).map_err(err_to_string)?;
    let z = batch
        .zips
        .iter()
        .find(|z| z.id == zip_id)
        .ok_or_else(|| "ZIPä¸å­˜åœ¨".to_string())?;
    let path = z
        .image_files
        .get(index)
        .ok_or_else(|| "å›¾ç‰‡ç´¢å¼•è¶Šç•Œ".to_string())?;
    let bytes = fs::read(path).map_err(err_to_string)?;
    let mime = guess_image_mime(path);
    let b64 = base64_encode(&bytes);
    Ok(format!("data:{mime};base64,{b64}"))
}

#[tauri::command]
fn save_pdf_page_screenshots(
    app: tauri::AppHandle,
    batch_id: String,
    zip_id: String,
    pdf_name: String,
    screenshots: Vec<String>,
) -> Result<Vec<String>, String> {
    let batch_dir = batch_dir(&app, &batch_id).map_err(err_to_string)?;
    let mut batch: BatchSummary = read_batch(&batch_dir).map_err(err_to_string)?;

    let zip = batch
        .zips
        .iter_mut()
        .find(|z| z.id == zip_id)
        .ok_or_else(|| "ZIPä¸å­˜åœ¨".to_string())?;

    let out_dir = batch_dir
        .join("zips")
        .join(&zip.id)
        .join("extracted")
        .join("pdf_screens")
        .join(sanitize_file_stem(&pdf_name));
    fs::create_dir_all(&out_dir).map_err(err_to_string)?;

    let mut saved = Vec::new();
    for (i, s) in screenshots.iter().enumerate() {
        let bytes = decode_data_url_base64(s).map_err(err_to_string)?;
        let out_path = out_dir.join(format!("page_{:03}.png", i + 1));
        fs::write(&out_path, bytes).map_err(err_to_string)?;
        let p = out_path.to_string_lossy().to_string();
        saved.push(p.clone());
        zip.pdf_page_screenshot_files.push(p);
    }

    let meta_path = batch_dir.join("batch.json");
    fs::write(&meta_path, serde_json::to_vec_pretty(&batch).map_err(err_to_string)?)
        .map_err(err_to_string)?;

    Ok(saved)
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ExcelPreviewData {
    sheet_name: String,
    rows: Vec<Vec<String>>,
    total_sheets: usize,
    sheet_names: Vec<String>,
}

fn read_excel_preview(excel_path: &Path) -> Result<ExcelPreviewData> {
    let extension = excel_path
        .extension()
        .and_then(|e| e.to_str())
        .unwrap_or("")
        .to_lowercase();

    println!("æ­£åœ¨è¯»å–Excelæ–‡ä»¶: {:?}, æ‰©å±•å: {}", excel_path, extension);

    if extension == "xlsx" {
        let mut workbook = calamine::open_workbook::<Xlsx<_>, _>(excel_path)
            .map_err(|e| anyhow!("æ‰“å¼€xlsxæ–‡ä»¶å¤±è´¥: {}", e))?;

        // Use the trait methods
        use calamine::Reader;
        let sheet_names = workbook.sheet_names();
        let first_sheet_name = sheet_names
            .first()
            .ok_or_else(|| anyhow!("Excelæ–‡ä»¶æ²¡æœ‰å·¥ä½œè¡¨"))?
            .to_string();

        println!("å·¥ä½œè¡¨åç§°: {:?}", sheet_names);

        // å°è¯•è¯»å–ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨çš„å®é™…æ•°æ®
        let mut rows = Vec::new();
        if let Ok(range) = workbook.worksheet_range(&first_sheet_name) {
            // é™åˆ¶è¯»å–å‰10è¡Œå’Œå‰10åˆ—ï¼Œé¿å…æ•°æ®è¿‡å¤š
            for row in range.rows().take(10) {
                let mut row_data = Vec::new();
                for cell in row.iter().take(10) {
                    let value_str = match cell {
                        calamine::Data::String(s) => s.to_string(),
                        calamine::Data::Float(f) => f.to_string(),
                        calamine::Data::Int(i) => i.to_string(),
                        calamine::Data::Bool(b) => b.to_string(),
                        calamine::Data::Empty => String::new(),
                        _ => "ã€æ•°æ®ã€‘".to_string(),
                    };
                    row_data.push(value_str);
                }
                rows.push(row_data);
            }
        } else {
            // å¦‚æœæ— æ³•è¯»å–æ•°æ®ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            return Err(anyhow!("æ— æ³•è¯»å–Excelå·¥ä½œè¡¨æ•°æ®: {}", first_sheet_name));
        }

        if rows.is_empty() {
            // å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè‡³å°‘è¿”å›è¡¨å¤´
            rows = vec![
                vec!["å·¥ä½œè¡¨".to_string(), first_sheet_name.to_string(), "".to_string()],
                vec!["çŠ¶æ€".to_string(), "æ— æ•°æ®".to_string(), "".to_string()],
            ];
        }

        Ok(ExcelPreviewData {
            sheet_name: first_sheet_name,
            rows,
            total_sheets: sheet_names.len(),
            sheet_names,
        })
    } else if extension == "xls" {
        let mut workbook = calamine::open_workbook::<Xls<_>, _>(excel_path)
            .map_err(|e| anyhow!("æ‰“å¼€xlsæ–‡ä»¶å¤±è´¥: {}", e))?;

        // Use the trait methods
        let sheet_names = workbook.sheet_names();
        let first_sheet_name = sheet_names
            .first()
            .ok_or_else(|| anyhow!("Excelæ–‡ä»¶æ²¡æœ‰å·¥ä½œè¡¨"))?
            .to_string();

        println!("å·¥ä½œè¡¨åç§°: {:?}", sheet_names);

        // å°è¯•è¯»å–ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨çš„å®é™…æ•°æ®
        let mut rows = Vec::new();
        if let Ok(range) = workbook.worksheet_range(&first_sheet_name) {
            // é™åˆ¶è¯»å–å‰10è¡Œå’Œå‰10åˆ—ï¼Œé¿å…æ•°æ®è¿‡å¤š
            for row in range.rows().take(10) {
                let mut row_data = Vec::new();
                for cell in row.iter().take(10) {
                    let value_str = match cell {
                        calamine::Data::String(s) => s.to_string(),
                        calamine::Data::Float(f) => f.to_string(),
                        calamine::Data::Int(i) => i.to_string(),
                        calamine::Data::Bool(b) => b.to_string(),
                        calamine::Data::Empty => String::new(),
                        _ => "ã€æ•°æ®ã€‘".to_string(),
                    };
                    row_data.push(value_str);
                }
                rows.push(row_data);
            }
        } else {
            // å¦‚æœæ— æ³•è¯»å–æ•°æ®ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            return Err(anyhow!("æ— æ³•è¯»å–Excelå·¥ä½œè¡¨æ•°æ®: {}", first_sheet_name));
        }

        if rows.is_empty() {
            // å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè‡³å°‘è¿”å›è¡¨å¤´
            rows = vec![
                vec!["å·¥ä½œè¡¨".to_string(), first_sheet_name.to_string(), "".to_string()],
                vec!["çŠ¶æ€".to_string(), "æ— æ•°æ®".to_string(), "".to_string()],
            ];
        }

        Ok(ExcelPreviewData {
            sheet_name: first_sheet_name,
            rows,
            total_sheets: sheet_names.len(),
            sheet_names,
        })
    } else {
        Err(anyhow!("ä¸æ”¯æŒçš„Excelæ ¼å¼: {}", extension))
    }
}


#[tauri::command]
fn get_excel_preview_data(
    app: tauri::AppHandle,
    batch_id: String,
    zip_id: String,
    index: usize,
) -> Result<ExcelPreviewData, String> {
    let batch_dir = batch_dir(&app, &batch_id).map_err(err_to_string)?;
    let batch: BatchSummary = read_batch(&batch_dir).map_err(err_to_string)?;
    let z = batch
        .zips
        .iter()
        .find(|z| z.id == zip_id)
        .ok_or_else(|| "ZIPä¸å­˜åœ¨".to_string())?;
    let path = z
        .excel_files
        .get(index)
        .ok_or_else(|| "Excelæ–‡ä»¶ç´¢å¼•è¶Šç•Œ".to_string())?;

    read_excel_preview(Path::new(path)).map_err(err_to_string)
}

fn sanitize_file_stem(name: &str) -> String {
    let base = Path::new(name)
        .file_stem()
        .and_then(|s| s.to_str())
        .unwrap_or("pdf");
    base.chars()
        .map(|c| {
            if c.is_ascii_alphanumeric() || c == '-' || c == '_' {
                c
            } else {
                '_'
            }
        })
        .collect::<String>()
}

fn decode_data_url_base64(data_url: &str) -> Result<Vec<u8>> {
    let (meta, b64) = data_url
        .split_once(',')
        .ok_or_else(|| anyhow!("data urlæ ¼å¼ä¸æ­£ç¡®"))?;
    if !meta.contains(";base64") {
        return Err(anyhow!("data urlä¸æ˜¯base64æ ¼å¼"));
    }
    base64_decode(b64)
}

fn base64_decode(s: &str) -> Result<Vec<u8>> {
    fn val(c: u8) -> Option<u8> {
        match c {
            b'A'..=b'Z' => Some(c - b'A'),
            b'a'..=b'z' => Some(c - b'a' + 26),
            b'0'..=b'9' => Some(c - b'0' + 52),
            b'+' => Some(62),
            b'/' => Some(63),
            _ => None,
        }
    }

    let bytes = s.as_bytes();
    let mut out = Vec::with_capacity((bytes.len() / 4) * 3);
    let mut buf = [0u8; 4];
    let mut n = 0usize;

    for &b in bytes {
        if b == b'=' {
            buf[n] = 64;
            n += 1;
        } else if let Some(v) = val(b) {
            buf[n] = v;
            n += 1;
        } else if b == b'\n' || b == b'\r' || b == b' ' || b == b'\t' {
            continue;
        } else {
            return Err(anyhow!("base64åŒ…å«éæ³•å­—ç¬¦"));
        }

        if n == 4 {
            out.push((buf[0] << 2) | (buf[1] >> 4));
            if buf[2] != 64 {
                out.push((buf[1] << 4) | (buf[2] >> 2));
            }
            if buf[3] != 64 {
                out.push((buf[2] << 6) | buf[3]);
            }
            n = 0;
        }
    }

    Ok(out)
}

fn guess_image_mime(path: &str) -> &'static str {
    let lower = path.to_ascii_lowercase();
    if lower.ends_with(".png") {
        "image/png"
    } else if lower.ends_with(".jpg") || lower.ends_with(".jpeg") {
        "image/jpeg"
    } else if lower.ends_with(".gif") {
        "image/gif"
    } else {
        "application/octet-stream"
    }
}

fn base64_encode(bytes: &[u8]) -> String {
    const TABLE: &[u8; 64] = b"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
    let mut out = String::with_capacity(((bytes.len() + 2) / 3) * 4);
    let mut i = 0usize;
    while i + 3 <= bytes.len() {
        let b0 = bytes[i];
        let b1 = bytes[i + 1];
        let b2 = bytes[i + 2];
        out.push(TABLE[(b0 >> 2) as usize] as char);
        out.push(TABLE[(((b0 & 0b0000_0011) << 4) | (b1 >> 4)) as usize] as char);
        out.push(TABLE[(((b1 & 0b0000_1111) << 2) | (b2 >> 6)) as usize] as char);
        out.push(TABLE[(b2 & 0b0011_1111) as usize] as char);
        i += 3;
    }

    let rem = bytes.len() - i;
    if rem == 1 {
        let b0 = bytes[i];
        out.push(TABLE[(b0 >> 2) as usize] as char);
        out.push(TABLE[((b0 & 0b0000_0011) << 4) as usize] as char);
        out.push('=');
        out.push('=');
    } else if rem == 2 {
        let b0 = bytes[i];
        let b1 = bytes[i + 1];
        out.push(TABLE[(b0 >> 2) as usize] as char);
        out.push(TABLE[(((b0 & 0b0000_0011) << 4) | (b1 >> 4)) as usize] as char);
        out.push(TABLE[((b1 & 0b0000_1111) << 2) as usize] as char);
        out.push('=');
    }

    out
}

// æ–°å¢ï¼šå¸¦æ–‡ä»¶åµŒå…¥çš„Wordå¯¼å‡ºå‘½ä»¤
#[tauri::command]
fn export_bundle_zip_with_embeddings(
    app: tauri::AppHandle,
    batch_id: String,
    embed_files: bool,
    max_file_size_mb: Option<u64>,
    allowed_types: Option<Vec<String>>,
) -> Result<String, String> {
    let batch_dir = batch_dir(&app, &batch_id).map_err(err_to_string)?;
    let mut batch: BatchSummary = read_batch(&batch_dir).map_err(err_to_string)?;

    // æŒ‰ä¸‹å‘æ—¶é—´æ’åº
    sort_zips_by_issued_at(&mut batch.zips);

    let now = OffsetDateTime::now_utc();
    let out = prompt_save_path(default_export_bundle_name(now), "zip", "ZIP")?;

    // åˆ›å»ºåµŒå…¥é…ç½®
    let mut config = EmbeddingConfig::default();
    if embed_files {
        config.enabled = true;
        if let Some(size_mb) = max_file_size_mb {
            config.max_file_size = (size_mb * 1024 * 1024) as usize;
        }
        if let Some(types) = allowed_types {
            config.allowed_types = types;
        }
    } else {
        config.enabled = false;
    }

    // ä½¿ç”¨å¢å¼ºçš„å¯¼å‡ºåŠŸèƒ½
    let (docx, embedded_files) = build_enhanced_summary_docx(&batch, embed_files).map_err(err_to_string)?;
    let docx_bytes = build_docx_with_embeddings(docx, &embedded_files).map_err(err_to_string)?;
    let bundle_bytes = build_bundle_zip_bytes(&batch, &docx_bytes).map_err(err_to_string)?;

    fs::write(&out, bundle_bytes).map_err(err_to_string)?;
    Ok(out.to_string_lossy().to_string())
}

// æ–°å¢ï¼šè·å–åµŒå…¥é…ç½®
#[tauri::command]
fn get_embedding_config() -> EmbeddingConfig {
    EmbeddingConfig::default()
}

#[cfg_attr(mobile, tauri::mobile_entry_point)]
pub fn run() {
    tauri::Builder::default()
        .manage(AppState::default())
        .invoke_handler(tauri::generate_handler![
            pick_zip_files,
            import_zips,
            export_excel,
            export_excel_with_selection,
            export_bundle_zip,
            export_bundle_zip_with_selection,
            export_bundle_zip_with_embeddings,
            get_embedding_config,
            open_path,
            get_preview_image_data,
            get_excel_preview_data,
            save_pdf_page_screenshots
        ])
        .setup(|app| {
            if cfg!(debug_assertions) {
                app.handle().plugin(
                    tauri_plugin_log::Builder::default()
                        .level(log::LevelFilter::Info)
                        .build(),
                )?;
            }
            Ok(())
        })
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}

#[cfg(test)]
mod tests {
    use super::*;

    fn fixture_zip(name: &str) -> PathBuf {
        PathBuf::from(env!("CARGO_MANIFEST_DIR"))
            .parent()
            .unwrap()
            .join("zip_simples")
            .join(name)
    }

    #[test]
    fn parse_fields_from_fixture_zip() {
        let zip_path = fixture_zip("202512110007-ZL1.zip");
        let scan = scan_zip(&zip_path).expect("scan_zip");
        let (fields, _videos) = extract_word_and_videos(&zip_path, &scan).expect("extract");
        assert!(!fields.instruction_no.is_empty());
        assert!(!fields.title.is_empty());
        assert!(!fields.issued_at.is_empty());
    }

    #[test]
    fn build_bundle_zip_has_per_zip_attachments_dir_and_docx_links() {
        let zip_path = fixture_zip("202512110028-ZL1.zip");
        let scan = scan_zip(&zip_path).expect("scan_zip");
        let (fields, _videos) = extract_word_and_videos(&zip_path, &scan).expect("extract");

        let tmp_root = std::env::temp_dir().join(format!("archivebox_test_{}", Uuid::new_v4()));
        fs::create_dir_all(&tmp_root).unwrap();
        let batch_dir = tmp_root.join("batch");
        fs::create_dir_all(&batch_dir).unwrap();

        let zip_id = Uuid::new_v4().to_string();
        let stored_zip = tmp_root.join(format!("{}.zip", zip_id));
        fs::copy(&zip_path, &stored_zip).unwrap();

        let mut zip_summary = ZipSummary {
            id: zip_id.clone(),
            filename: "202512110028-ZL1.zip".to_string(),
            source_path: zip_path.to_string_lossy().to_string(),
            stored_path: stored_zip.to_string_lossy().to_string(),
            extracted_dir: String::new(),
            include_original_zip: true,
            status: "completed".to_string(),
            word: fields,
            has_video: !scan.video_entries.is_empty(),
            has_sample: scan.has_sample,
            video_entries: scan.video_entries.clone(),
            video_files: vec![],
            image_files: vec![],
            pdf_files: vec![],
            pdf_page_screenshot_files: vec![],
            excel_files: vec![],
        };

        extract_preview_files(&batch_dir, &zip_id, &stored_zip, &scan, &mut zip_summary)
            .expect("extract_preview_files");

        let batch = BatchSummary {
            batch_id: "batch_test".to_string(),
            created_at: OffsetDateTime::now_utc().unix_timestamp(),
            zips: vec![zip_summary.clone()],
        };

        let docx_bytes = build_summary_docx(&batch).expect("build_summary_docx");
        assert!(!docx_bytes.is_empty());

        // docx å†…åº”æœ‰æŒ‡å‘ attachments/<zipId>/ çš„é“¾æ¥å…³ç³»
        let mut docx_zip = ZipArchive::new(Cursor::new(&docx_bytes)).expect("docx zip");
        let mut rels = String::new();
        docx_zip
            .by_name("word/_rels/document.xml.rels")
            .expect("rels exists")
            .read_to_string(&mut rels)
            .unwrap();
        assert!(
            rels.contains(&format!("attachments/{}/", zip_id)),
            "rels should contain per-zip attachments link"
        );

        let bundle = build_bundle_zip_bytes(&batch, &docx_bytes).expect("bundle");
        let mut out_zip = ZipArchive::new(Cursor::new(bundle)).expect("bundle zip");

        // attachments/ ç›®å½•æƒé™åº”ä¸º 0755ï¼Œä¸”å¿…é¡»åŒ…å« attachments/<zipId>/
        let attachments_dir_mode = out_zip
            .by_name("attachments/")
            .expect("attachments dir")
            .unix_mode()
            .unwrap_or(0);
        assert_eq!(attachments_dir_mode & 0o777, 0o755);
        let per_zip_dir_mode = out_zip
            .by_name(&format!("attachments/{}/", zip_id))
            .expect("per zip dir")
            .unix_mode()
            .unwrap_or(0);
        assert_eq!(per_zip_dir_mode & 0o777, 0o755);

        // æ¯ä¸ªZIPç›®å½•ä¸‹å¿…é¡»åŒ…å«åŸå§‹ZIP
        out_zip
            .by_name(&format!("attachments/{}/{}", zip_id, zip_summary.filename))
            .expect("zip copied into per zip dir");
    }
}
